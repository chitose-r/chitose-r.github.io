<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>EVSegNet-paper | Chitose-Blog</title><meta name="author" content="Chitose"><meta name="copyright" content="Chitose"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="EV-SegNet: Semantic Segmentation for Event-based Cameras EV-SegNet:基于事件相机的语义分割29 November, 2018 摘要​    事件相机是非常有前景的传感器，相较于基于帧的相机，它们展现出了多个优势。基于深度学习的方法在视觉识别任务中领先于现有技术，并且潜在地可以利用这些相机的优势，但是为了有效地处理事件数据，仍然需要进">
<meta property="og:type" content="article">
<meta property="og:title" content="EVSegNet-paper">
<meta property="og:url" content="https://www.chitose.cn/EVSegNet-paper/index.html">
<meta property="og:site_name" content="Chitose-Blog">
<meta property="og:description" content="EV-SegNet: Semantic Segmentation for Event-based Cameras EV-SegNet:基于事件相机的语义分割29 November, 2018 摘要​    事件相机是非常有前景的传感器，相较于基于帧的相机，它们展现出了多个优势。基于深度学习的方法在视觉识别任务中领先于现有技术，并且潜在地可以利用这些相机的优势，但是为了有效地处理事件数据，仍然需要进">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_2.png">
<meta property="article:published_time" content="2024-02-04T14:10:03.000Z">
<meta property="article:modified_time" content="2024-02-04T19:26:59.000Z">
<meta property="article:author" content="Chitose">
<meta property="article:tag" content="演示">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_2.png"><link rel="shortcut icon" href="https://www.fomal.cc/favicon.ico"><link rel="canonical" href="https://www.chitose.cn/EVSegNet-paper/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'EVSegNet-paper',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-05 03:26:59'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://www.fomal.cc/static/css/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Face.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_2.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Chitose-Blog"><span class="site-name">Chitose-Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">EVSegNet-paper</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-04T14:10:03.000Z" title="发表于 2024-02-04 22:10:03">2024-02-04</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-04T19:26:59.000Z" title="更新于 2024-02-05 03:26:59">2024-02-05</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>26分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="EVSegNet-paper"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="EV-SegNet-Semantic-Segmentation-for-Event-based-Cameras"><a href="#EV-SegNet-Semantic-Segmentation-for-Event-based-Cameras" class="headerlink" title="EV-SegNet: Semantic Segmentation for Event-based Cameras"></a>EV-SegNet: Semantic Segmentation for Event-based Cameras</h1><blockquote>
<h1 id="EV-SegNet-基于事件相机的语义分割"><a href="#EV-SegNet-基于事件相机的语义分割" class="headerlink" title="EV-SegNet:基于事件相机的语义分割"></a>EV-SegNet:基于事件相机的语义分割</h1><h2 id="29-November-2018"><a href="#29-November-2018" class="headerlink" title="29 November, 2018"></a>29 November, 2018</h2></blockquote>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>​    事件相机是非常有前景的传感器，相较于基于帧的相机，它们展现出了多个优势。基于深度学习的方法在视觉识别任务中领先于现有技术，并且潜在地可以利用这些相机的优势，但是为了有效地处理事件数据，仍然需要进行一些适配。本研究引入了使用此类数据进行语义分割的首个基线模型。我们基于最先进的技术构建了一个仅以事件信息作为输入的语义分割卷积神经网络。此外，我们提出了一种新的DVS数据表示方法，它在相关任务中的表现超过了之前使用的事件表示法。由于这个任务尚不存在标注好的数据集，我们提出了一种自动生成DDD17数据集部分序列的近似语义分割标签的方法，并且我们将这些标签与模型一起发布，并证明它们有效于训练仅使用DVS数据的模型。我们将使用DVS数据进行的语义分割结果与使用对应灰度图像的结果进行了比较，展示了两者是互补的，并且值得结合使用。</p>
<h2 id="补充材料"><a href="#补充材料" class="headerlink" title="补充材料"></a>补充材料</h2><p>​    我们的方法在测试序列中的表现视频可在此链接查看：<a target="_blank" rel="noopener" href="https://youtu.be/YQXBjWUSiaA。我们已经发布了数据集和代码，链接为：https://github.com/Shathe/Ev-SegNet。">https://youtu.be/YQXBjWUSiaA。我们已经发布了数据集和代码，链接为：https://github.com/Shathe/Ev-SegNet。</a></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EVS-Figure1.png" alt=""></p>
<blockquote>
<p><strong>图1所示</strong>。基于事件相机数据(中间)的两个语义分割示例(左)。语义分割是我们的CNN的预测，只提供事件数据。显示灰度图像(右)只是为了方便可视化。</p>
</blockquote>
<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>​    动态视觉传感器（DVS）作为一种充满前景的事件相机，能够注册捕获环境中的强度变化。与传统相机不同，这种传感器不是以固定的帧率获取图像。正如它们的名字所示，这些相机捕获事件并记录异步事件流。一个事件表明在特定时刻和特定像素点发生了强度变化（关于事件获取的更多细节，请参见第3.2节）。事件相机相较于更传统的相机提供了多重优势，1）主要是其极高的时间分辨率，能够在微秒内捕获多个事件；2）极高的动态范围，可以在困难的光照环境下捕获信息；3）低功耗和带宽要求。Maqueda等人[24]在他们的工作中展示了视觉识别任务如何从这些优势中受益，强调事件相机是天然的运动检测器，并自动过滤掉任何时间上冗余的信息。此外，他们展示了这些相机提供的信息不仅仅是减去连续的传统图像那么简单。</p>
<p>​    这些相机为许多计算机视觉应用提供了新的可能性和特性，可能会增强解决方案。然而，仍需要开发新的算法以充分利用它们的能力，尤其是在识别任务方面。针对图像数据的基于深度学习的最新成果尚未在事件相机上尝试过。该工作的主要原因之一是这些相机的输出：它们没有提供标准的图像，而且还没有一种明确被采纳的方法来表示事件流以供卷积神经网络（CNN）使用。另一个挑战是缺乏标记的训练数据，这是训练大多数识别模型的关键。我们的工作包含了简单但有效的新颖想法来应对这两大挑战。这些想法对于许多DVS应用可能有所帮助，但我们关注的是一个尚未用此传感器探索过的应用，即语义分割。</p>
<p>​    本研究提出了将事件相机的潜力与深度学习技术结合在一起，应用于语义分割这一挑战性任务上。语义分割直观上似乎更适合使用外观信息的模型。然而，我们展示了如何通过合适的模型和表示方法，事件相机为这一任务提供了非常有前途的结果。</p>
<p>​    图1展示了我们工作输出的两个视觉结果示例。我们的主要贡献是：</p>
<ul>
<li>据我们所知，首次使用DVS数据进行语义分割的结果。我们构建了一个基于Xception的CNN，将此数据作为输入。由于没有现成的基准测试，我们提出了如何为DDD17基于事件的数据集的某些序列生成近似的语义分割标签。模型和数据正在发布中。</li>
<li>对不同DVS数据表示在语义分割上的性能进行了比较（包括一种新提出的表示方法，被证明优于现有方法），并分析了与传统图像相比的优势和劣势。</li>
</ul>
<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><h3 id="2-1-事件相机应用"><a href="#2-1-事件相机应用" class="headerlink" title="2.1 事件相机应用"></a>2.1 事件相机应用</h3><p>​    如前所述，事件相机在许多情况下相较于传统相机提供了有价值的优势。我们发现最近的研究在多项通常由传统视觉传感器解决的任务中证明了这些优势。这些工作中的大多数集中在3D重建[28, 19, 35, 34]和6自由度相机跟踪[29, 11]的努力。尽管基于RGB图像的3D重建和定位解决方案已经非常成熟，但现有算法不能以完全相同的方式应用于事件相机。上述工作提出了不同的适应性方法。</p>
<p>​    我们还发现了一些探索这些相机在其他任务中应用的新方法，如光流估计[12, 23, 36]或者更接近我们目标任务的物体检测和识别[26, 6, 20, 30]。关于这些识别工作中使用的数据，Orchard等人[26]和Lagorce等人[20]在小型数据集上执行了识别任务，主要检测字符和数字。最新的研究开始使用更具挑战性的（但稀缺的）真实场景录制，如在Sironi等人[30]中使用的N-CARS数据集，或我们在本研究中使用的DDD17数据集[2]，因为它包含了真实世界的城市场景。</p>
<p>​    这些方法大多有一个共同的第一步：将事件信息编码成类图像表示，以便于处理。</p>
<p>​    我们在第3节详细讨论了不同的先前工作事件表示（编码空间和时间信息）以及我们提出的表示（对时间信息有不同的编码方式）。</p>
<h3 id="2-2-语义分割"><a href="#2-2-语义分割" class="headerlink" title="2.2 语义分割"></a>2.2 语义分割</h3><p>​    语义分割是一个视觉识别问题，其目标是为图像中的每个像素分配一个语义标签。目前，该问题的最先进解决方案主要是基于深度学习的，它们大多提出了不同变体的编码器-解码器CNN架构[5, 4, 17, 16]。</p>
<p>​    现有的一些语义分割解决方案针对的是实例级语义分割，例如，MaskRCNN[15]，包括三个主要步骤：区域提议、二值分割和分类。其他解决方案，如DeepLabv3+[5]，则针对类级语义分割。DeepLabv3+是Xception[7]的全卷积扩展，Xception也是图像分类的最先进架构，并且是我们工作的基础架构。由朱等人[37]进行的图像分割综述提供了语义分割更传统解决方案的详细汇编，而加西亚等人[13]则讨论了基于深度学习的语义分割的更近期方法，涵盖了从新架构到常见数据集。</p>
<p>​    迄今为止讨论的工作展示了使用RGB图像进行语义分割的CNNs的有效性。与我们的工作更为接近的是，我们发现其他工作在使用标准RGB图像之外的额外输入数据模态进行语义分割任务时也表现出了优异的性能。例如，语义分割的一个常见的额外输入数据是深度信息。曹等人[3]和古普塔等人[14]是如何使用卷积神经网络将RGB图像与深度信息结合起来的两个很好的例子。同样，在机器人领域非常常见的传感器，激光雷达传感器，也被证明在执行语义分割时能提供有用的额外信息[32, 10]。其他工作展示了如何结合较少见的模态，如荧光信息[1]，或如何在多光谱图像[10]上执行语义分割。用于医学图像分析的语义分割任务[22]通常也会应用或适应为RGB图像设计的基于CNN的方法到不同的医学成像传感器，如MRI图像[18]和CT数据[8]。</p>
<p>​    我们的工作聚焦于一个不同的模态，即事件相机数据，这在之前的语义分割工作中尚未探索。我们基于RGB图像上语义分割性能最优的模型之一[5]，使用Xception设计[7]来构建一个用于事件图像上的语义分割的编码器-解码器架构。我们的实验显示，仅使用来自公开基准[2]的事件数据就能获得良好的语义分割结果，接近于在相同场景下标准图像所达到的结果。我们还证明了当将这一模态与标准相机结合使用时，可以为更准确地解决这一问题带来补充性的好处。</p>
<h2 id="3-从事件到语义分割"><a href="#3-从事件到语义分割" class="headerlink" title="3 从事件到语义分割"></a>3 从事件到语义分割</h2><p>​    在本节中，我们将讨论视觉识别任务中使用的不同事件表示，以便最终提出用于语义分割的事件数据的丰富编码。    </p>
<h3 id="3-1-事件数据"><a href="#3-1-事件数据" class="headerlink" title="3.1 事件数据"></a>3.1 事件数据</h3><p>​    事件相机捕捉每个像素的强度变化。事件相机的输出不是传统相机的三维图像(高度、宽度和通道)，而是事件流。事件表示强度信号的对数(超过既定阈值σ)的正或负变化:</p>
<script type="math/tex; mode=display">
\log(I_{t+1}) - \log(I_t) \geq \sigma,</script><p>​    在两个连续时间戳捕获的强度为$I_{t+1}$和$I_t$。每个事件$(e_i)$由四个不同的组成部分定义：像素的两个坐标（$x_i$, $y_i$）是在哪里测量到变化，一个可能为正或负的极性（$p_i$），以及一个时间戳（$t_i$​）：</p>
<script type="math/tex; mode=display">
e_i = \{x_i, y_i, p_i, t_i\}.</script><p>​    事件是异步的，并具有所描述的编码，该编码在构造上并不提供适合广泛使用的视觉识别任务技术（如CNNs）的良好输入。也许最直接的表示方法是一个$n \times 4$矩阵，其中$n$​是事件数量。但显然，这种表示没有编码事件之间的空间关系。已经提出了几种策略，这些策略成功地将这些信息编码成在不同应用中成功应用的密集表示。</p>
<h3 id="3-2-事件表示"><a href="#3-2-事件表示" class="headerlink" title="3.2 事件表示"></a>3.2 事件表示</h3><p>​    <strong>基本的事件位置密集编码。</strong>最成功应用的事件数据表示方法是创建一个图像，其中包含几个通道，编码以下信息。它在每个位置（$x_i, y_i$）存储在任何时间(t_i)内发生在那里的事件信息，其中$t_i$在一个设定的集成间隔大小$T$内。这种表示的变体已被许多先前的工作使用，显示在非常不同的应用中的出色性能：光流估计[36]，对象检测[6]，分类[20, 27, 30]和回归任务[24]。</p>
<p>​    早期的工作只使用一个通道来编码事件发生。Nguyen等人[25]存储了每个像素中发生的最后一个事件的信息，即，选择表示正事件，负事件或没有事件的对应值。一个重要的缺点是只保留了最后一个事件的信息。</p>
<p>​    在一个更完整的表示中，最近一个关于方向盘角度估计的工作，由Maqueda等人[24]进行，将正和负事件发生存储到两个不同的通道中。换句话说，这种表示（Hist）编码了在每个像素（(x_i, y_i)）发生的正和负事件的2D直方图，如下所述：</p>
<script type="math/tex; mode=display">
Hist(x, y, p) = \sum_{i=1, t_i \in W}^{N} \delta(x_i, x) \delta(y_i, y) \delta(p_i, p)</script><p>​    在此，$\delta$ 是克罗内克$\delta$函数（如果变量相等，该函数值为1，否则为0），$W$ 是考虑汇总事件信息的时间窗口或间隔，$N$ 是在间隔$W$内发生的事件数量。因此，乘积 $\delta(x_i, x)\delta(y_i, y)\delta(p_i, p)$ 表示事件$e_i$是否在其坐标$x_i, y_i$与$x, y$值和其极性$p_i$与$p$匹配。这种表示有两个通道，每个极性$p$（正事件和负事件）一个通道。我们稍后描述的提议表示将利用这两个直方图通道。</p>
<p>​    请注意，到目前为止讨论的所有表示仅使用时间信息（时间戳(t_i)）来查看每个事件所属的时间间隔。</p>
<p>​    <strong>包括时间信息的密集编码。</strong>然而，时间信息，即每个事件的时间戳$t_i$，包含对识别任务有用的信息，已经显示将每个事件的这种非空间信息包含到类图像编码中是有用的。Lagorce等人[20]提出了一个2通道图像，每个极性一个通道，称为时间表面。他们存储在集成间隔$W$期间最近的事件时间戳相关的每个像素的信息。后来，Sironi等人[30]通过改变时间表面的定义来增强这个先前的表示。他们现在计算每个像素的值，结合了在$W$内发生的所有事件的时间戳信息。</p>
<p>​    Zhu等人[36]最近提出的另一种方法介绍了一种更完整的表示，它包括来自Maqueda等人[24]的事件发生直方图的两个通道，以及包含时间信息的另外两个通道。这两个通道（Recent）分别存储在集成间隔期间在该位置发生的最近正事件或负事件的标准化时间戳的每个像素$(x_i, y_i$）。</p>
<script type="math/tex; mode=display">
\text{Recent}(x, y, p) = \max_{t_i \in W} t_i \delta(x_i, x) \delta(y_i, y) \delta(p_i, p)</script><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EVS-Figure2.png" alt=""></p>
<blockquote>
<p><strong>图2所示</strong>。在3.2节中解释了来自负极性事件($p$ =-1)的数据的不同1通道编码的可视化(在0到255灰度值之间)。在这些示例中，事件信息集成的时间间隔为50ms ($T$= 50ms)。灰度为参考值。</p>
</blockquote>
<p>​    所有这些最近的表示都将事件时间戳和直方图归一化为在间隔$W$内的相对值。</p>
<p>​    受到所有这些先前工作的启发，我们提出了一种替代表示，结合了迄今为止所展示的最佳想法：2通道的事件直方图来编码事件的空间分布，以及在集成时间间隔期间发生的所有时间戳的信息。</p>
<p>​    <strong>我们提出的表示。</strong>我们提出了一个6通道图像表示。前两个通道是正事件和负事件的直方图（公式3）。其余四个通道是一种简单但有效的方式，用于存储在间隔(W)期间发生的所有事件时间戳相关的信息。我们可以将其视为一种存储它们如何沿着(T)分布的方式，而不是仅选择其中的一个时间戳。我们建议存储在每个像素（(x_i, y_i)）发生的事件的标准化时间戳的平均值（(M)）和标准偏差（(S)），分别为正事件和负事件分别计算，如下所示：</p>
<script type="math/tex; mode=display">
M(x, y, p) = \frac{1}{\text{Hist}(x, y, p)} \sum_{i=1, t_i \in W}^N t_i \delta(x_i, x) \delta(y_i, y) \delta(p_i, p)</script><script type="math/tex; mode=display">
S(x, y, p) = \sqrt{\frac{\sum_{i=1, t_i \in W}^N (t_i \delta(x_i, x) \delta(y_i, y) \delta(p_i, p) - M(x, y, p))^2}{\text{Hist}(x, y, p) - 1}}.</script><p>​    然后，我们的表示由这六个二维通道组成：$Hist(x, y, -1)$，$Hist(x, y, +1)$，$M(x, y, -1)$，$M(x, y, +1)$，$S(x, y, -1)$，$S(x, y, +1)$。图2展示了这些通道的一些可视化效果。在事件表示图像中，像素越亮，编码的值越高，例如，白色意味着$Hist(x, y, -1)$中负事件的最高数量。</p>
<h3 id="3-3-事件数据的语义分割"><a href="#3-3-事件数据的语义分割" class="headerlink" title="3.3 事件数据的语义分割"></a>3.3 事件数据的语义分割</h3><p>​    已经证明CNN在密集的事件数据表示上工作得很好，这在前一节[24, 36]中有详细说明，因此我们探索了一个基于CNN的架构来学习一个不同的视觉任务，语义分割。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EVS-Figure3.png" alt=""></p>
<blockquote>
<p><strong>图3。</strong>基于事件的摄像机的语义分割。我们使用我们基于Xception[7]的编码器-解码器架构处理不同的2D事件数据编码（更多信息，请参见第3.3节详细信息）。最佳彩色观看。</p>
</blockquote>
<p>​    语义分割通常被建模为每像素分类，因此语义分割模型的输出具有与输入相同的分辨率。如前所述，使用RGB数据和额外模态，已经有很多最近成功的基于CNN的方法来解决这个问题。我们建立了一个受当前语义分割CNN最先进技术启发的架构，稍微调整以使用事件数据编码。相关工作通常遵循编码器-解码器架构，正如我们所做的那样。作为编码器，我们使用众所周知的Xception模型[7]，它已被证明在分类[7]和语义分割任务[5]中胜过其他编码器。作为解码器，也是遵循最先进工作[4, 5]，我们构建了一个轻量级解码器，将繁重的计算集中在编码器上。我们的架构还包括了最成功的最新模型的特性，包括：使用跳过连接来帮助深度架构的优化[16, 17]以避免梯度消失问题，以及使用辅助损失[33]，这也改善了学习过程的收敛。图3显示了本工作中构建的架构图，其中多通道事件表示作为网络输入。</p>
<p>​    与类似的架构一样，我们通过损失的反向传播进行训练优化，损失计算为所有每像素损失的总和，通过参数梯度。我们使用常见的soft-max交叉熵损失函数（$L$）进行计算，如公式(7)所述：其中$N$是标记像素的数量，$M$是类别的数量。$y<em>{c,j}$是像素$j$属于类别$c$的二进制指示器（真实情况）。$\hat{y}</em>{c,j}$是CNN预测的像素$j$属于类别$c$​的概率。</p>
<script type="math/tex; mode=display">
\mathcal{L} = -\frac{1}{N} \sum_{j=1}^N \sum_{c=1}^M y_{c,j} \ln (\hat{y}_{c,j})</script><p>​    由于N是标记像素的数量，M是类别的数量。$y<em>{c,j}$ 是像素j属于类别c（真实情况）的二进制指示符。$\hat{y}</em>{c,j}$​ 是CNN预测的像素j属于类别c的概率。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EVS-Table1.png" alt=""></p>
<blockquote>
<p><strong>表1。</strong>由DDD17数据集某些序列的几个区间组成的Ev-Seg数据摘要</p>
</blockquote>
<h2 id="4-Ev-Seg-事件分割数据"><a href="#4-Ev-Seg-事件分割数据" class="headerlink" title="4. Ev-Seg: 事件分割数据"></a>4. Ev-Seg: 事件分割数据</h2><p>​    Ev-Seg数据是DDD17数据集[2]的语义分割扩展。DDD17数据集包括了40个不同驾驶设置的序列。这些序列在不同的场景中被记录（例如，高速公路和城市场景）。该数据集提供了同步的灰度和基于事件的信息，但是，它没有提供语义分割标签。</p>
<p>​    我们的扩展包括生成的（自动生成的，非手动注释的）语义分割标签，作为该数据集大部分的真实标记使用。除了标签，为了便于复制和进一步的实验，我们还发布了选定的灰度图像子集和相应的事件数据，这些数据用三种不同的表示编码（Maqueda等人[24]，Zhu等人[36]和本文提出的新方法）。</p>
<p>​    <strong>生成标签。</strong>除了手动标记每个像素的语义分割真实情况的明显负担之外，如果我们考虑直接在基于事件的数据上执行这项任务，它甚至更具挑战性。我们只需要看看任何一个可用的事件表示（见图1），就会意识到如果没有灰度图像并排显示，人眼很难在那里区分出许多类别。其他研究已经表明，CNNs对于噪声训练[31]或近似标签[1]是稳健的，包括Chen等人[6]的工作，他们也成功地使用从灰度图生成的标签进行基于事件的数据中的对象检测。因此，我们提出使用相应的灰度图像生成一个近似的标签集来进行训练，我们证明这足以训练模型直接在基于事件的数据上进行分割。</p>
<p>​    为了生成这些近似的语义标签，我们执行了以下三个步骤。</p>
<p>​    首先，我们在众所周知的城市环境数据集Cityscapes[9]上训练了一个CNN进行语义分割，但使用的是灰度图像。用于此步骤的架构与3.3小节中描述的架构相同，它遵循了语义分割的最新技术组件。这个灰度分割模型经过70个周期的训练，学习率为1e-4。最终模型在Cityscapes验证数据上获得了83%的类别MIoU。这仍然与该数据集上使用RGB图像获得的顶尖结果（92%MIoU）有些距离，但对于我们的过程来说质量已经足够。</p>
<p>​    其次，使用这个灰度模型，我们获得了选定序列的所有灰度图像的语义分割（我们接下来详细说明哪些序列被使用以及为什么）。这些分割是我们将考虑用来训练我们基于事件的分割模型的标签。</p>
<p>​    最后，作为生成标签的最终后处理步骤，我们裁剪了所有图像的底部部分，即图像底部的60行，它总是包含汽车仪表板，并且只会在生成的标签中引入噪声。</p>
<p>​    <strong>DDD17序列子集选择。</strong>如前所述，我们没有为所有DDD17数据生成标签。我们接下来讨论我们遵循的原因和选择标准。<br>​    部分DDD17序列在通过CNN时没有给出很好的标签。这有几个原因。由于可用于训练基本灰度语义分割模型的数据域为城市域cityscape数据，因此我们只选择城市场景中的DDD17序列。此外，只有具有足够对比度(不太亮也不太暗)的图像才有可能提供良好的生成的地面真值。因此，我们只选择在白天拍摄的序列，没有过度曝光。在这些限制条件下，只有6个序列与它们近似匹配。因此，我们对应用了限制的每个序列中的间隔执行了更详细的手工注释(详细信息见表1)。</p>
<p>​    <strong>数据摘要。</strong>表1显示了Ev-Seg数据的内容的摘要。从前面详细选择的六个序列中，五个序列用作训练数据，一个序列用于测试。我们选择测试具有更均匀类分布的序列，即包含更多类别标签的序列它看起来不像人/行人标签</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EVS-Figure4.png" alt=""></p>
<blockquote>
<p><strong>图4。</strong>测试顺序示例。根据灰度图像（左）生成语义标签图像（右）通过在灰度版城市景观上训练的CNN。</p>
</blockquote>
<p>​    这些标签的类别与众所周知的相同Cityscapes数据集[9]（见表1），除了天空和建筑类别。尽管这两种猫的自负在Cityscapes数据集中得到了正确的学习，当使用对DDD17数据集执行推断时灰度图像，由于域偏移，这些类别没有正确生成。因此，在我们的实验中，这两个类别是一起学习的，就好像它们是同样的事情。城市景观之间的领域转换DDD17数据集也是生成城市景观类别而非类别。</p>
<p>​    图4显示了灰度图像和对应生成的属于我们DDD17数据集的扩展。我们可以看到，尽管标签并不像手动注释那样完美（以及如前所述，类，如建筑和天空不是仅使用灰度正确学习的），它们是非常准确和明确。</p>
<h2 id="5-实验验证"><a href="#5-实验验证" class="headerlink" title="5 实验验证"></a>5 实验验证</h2><h3 id="5-1-实验设置和度量"><a href="#5-1-实验设置和度量" class="headerlink" title="5.1 实验设置和度量"></a>5.1 实验设置和度量</h3><p>​    <strong>度量。</strong>我们的工作涉及语义分割问题，即使用事件摄像机的每像素分类。因此，我们根据标准指标评估我们的结果分类和语义分割：准确性和并集上的平均交集（$MIoU$）。</p>
<p>​    在语义分割中，给定一个预测图像$\hat{y}$和一个真实图像$y$，它们的像素数为$N$，可以分类为$C$​个不同的类别，准确度指标，公式（8）计算如下：</p>
<script type="math/tex; mode=display">
\text{Accuracy}(y, \hat{y}) = \frac{1}{N} \sum_{i=1}^{N} \delta(y_i, \hat{y}_i)</script><p>​    而MIoU则按类别计算为：</p>
<script type="math/tex; mode=display">
\text{MIoU}(y, \hat{y}) = \frac{1}{C} \sum_{j=1}^{C} \frac{\sum_{i=1}^{N} \delta(y_{i,c}, 1) \delta(\hat{y}_{i,c}, 1)}{\max(1, \delta(y_{i,c}, 1) + \delta(\hat{y}_{i,c}, 1))}</script><p>​    其中$\delta$表示克罗内克$\delta$函数，$y<em>i$指示像素$i$所属的类别，$y</em>{i,c}$是一个布尔值，表示像素$i$是否属于某个特定类别$c$。</p>
<p>​    <strong>设置。</strong>我们使用第3.3节中解释的CNN和第4节详细描述的Ev-Seg数据进行实验。我们从头开始训练所有模型变体，使用：初始学习率为1e-4的Adam优化器和多项式学习率衰减时间表。我们使用8的批量大小进行了30K次迭代训练，在训练期间我们执行了几个数据增强步骤：裁剪，旋转（-15°, 15°），垂直和水平移动（-25%，25%）和水平翻转。关于事件信息编码，对于训练，我们始终使用50ms的积分时间间隔，这已被证明在这个数据集[24]上表现良好。</p>
<h3 id="5-2节-事件语义分割"><a href="#5-2节-事件语义分割" class="headerlink" title="5.2节 事件语义分割"></a>5.2节 事件语义分割</h3><p>​    输入表示比较。一个好的输入表示对于CNN来说非常重要，以便正确学习和利用输入信息。表2比较了使用不同输入表示训练的几个语义分割模型。前三行对应于基于事件的表示。我们比较了一个基本的事件位置密集编码，一个也包含时间信息的密集编码，以及我们提出的编码（参见第3.2节了解详细信息）。我们的事件编码在不同的指标和评估上都略微但一致地在语义分割任务上表现更好。图5显示了这些结果的一些视觉示例。</p>
<p>​    所有模型（相同的架构，只是用不同的输入训练）都已使用50ms的积分间隔编码的数据进行了训练，但我们也使用不同的间隔大小对它们进行了评估。这是一个有趣的评估，因为通过改变聚合事件信息的时间间隔，我们在某种程度上模拟了不同的相机移动速度。换句话说，50ms或10ms的间隔可能会以不同的速度编码完全相同的运动。这一点非常重要，因为在实际场景中，模型必须在不同的速度下表现良好。我们可以看到，所有模型在使用与训练期间使用的积分时间（50ms）不同的间隔大小（10ms，250ms）编码的测试数据上的表现仅略有下降，参见图6示例。模型在不同积分间隔上表现相似有两个主要解释：1）编码是标准化的，2）训练数据包含不同的相机速度。这两件事都有助于在不同的时间间隔或移动速度上更好地泛化。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EVS-Table2.png" alt=""></p>
<blockquote>
<p><strong>表2.</strong>不同输入表示在测试Ev-Seg数据上的语义分割性能。使用时间间隔训练的模型(T)为50ms，但测试了不同的T值:50ms, 10ms和250ms。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EVS-Figure5.png" alt=""></p>
<blockquote>
<p><strong>图5。</strong>基于Ev-Seg数据的多幅测试图像语义分割。仅使用事件数据的不同输入表示的结果;(b)至(d)，或使用灰度数据(e)和(f)。为了可视化目的，显示了灰度原始图像(a)和地面真值标签。模型训练和测试的时间间隔为50ms。最好以彩色观看。</p>
</blockquote>
<p>​    <strong>事件相机与传统相机。</strong>表2还包括了在底部两行使用相应的灰度图像进行语义分割任务的结果。</p>
<p>​    尽管传统相机捕获的纯外观信息比事件相机丰富，但事件相机提供的运动信息对于语义分割任务也非常有用。从图5(e), (f)中使用灰度数据的结果示例中，我们可以看到事件信息如何帮助更好地分割移动对象，例如行人（在这些示例中以红色表示）或精细化对象边界。传统相机在检测小物体方面存在困难，一般来说，在极端照明（明亮或黑暗）条件下识别任何物体都会受到影响，而事件相机在识别没有移动的物体（因为它们与相机移动速度相同或因为它们太远而无法欣赏到它们的移动）方面更有困难。</p>
<p>​    单独使用传统相机进行语义分割比单独使用基于事件的相机表现更好。然而，我们的结果表明，结合使用两者进行语义分割会得到更好的结果。这表明它们学习到了互补的信息。有趣的是，我们应该注意训练和评估可用的数据正是我们能够正确分割灰度图像的数据，因此对灰度图像比基于事件的数据稍微有利一些（即，评估集中没有包括夜间图像，因为没有这些的真实标签）。</p>
<p>​    从我们的实验中得出两个明显的互补情况：1）一方面，众所周知，事件相机的主要缺点之一是与相机静止的物体不会触发事件，即，是不可见的。图7显示了一个在人行横道等待的汽车的例子，我们看到虽然传统相机可以完美地看到整个场景，但事件相机几乎没有捕捉到任何信息；2）另一方面，事件相机能够在传统视觉传感器根本看不到场景物体的情况下捕捉到有意义的信息，例如，在困难的照明环境下。这是由于它们高动态范围的缘故，图8展示了一个例子，在这个例子中，无论是灰度模型还是基于事件的模型都没有被训练过。由于输入表示上的领域偏移较小，基于事件的模型表现得更好。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EMS-Figure6.png" alt=""></p>
<blockquote>
<p><strong>图6。</strong>语义分割结果(下图)使用不同事件数据表示(顶部)的集成间隔大小(T)。仅在50ms上训练的模型得到的结果集成用我们建议的表示编码的事件信息。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EVS-Figure7.png" alt=""></p>
<blockquote>
<p><strong>图7。</strong>静态se序列上的语义分割结果(下图)，即在十字路口等待的汽车。这是一个明显的广告事件相机的情况，由于缺乏事件信息。</p>
</blockquote>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/EVS-Figure8.png" alt=""></p>
<blockquote>
<p>图8。极端光照的语义分割(下)具有不同输入表示的条件(夜间)(顶部):灰度图像和我们的事件数据表示。相应的模型只在光照良好的日间样本上训练。这是对于传统摄像机来说，这是一个明显的对抗案例，因为缺乏灰度捕获中的信息。</p>
</blockquote>
<h2 id="6-结论与未来工作"><a href="#6-结论与未来工作" class="headerlink" title="6 结论与未来工作"></a>6 结论与未来工作</h2><p>​    这项工作包括使用事件相机信息进行语义分割的第一个结果。我们建立一个编码器-解码器架构，该架构仅能从事件相机数据中学习语义tic分割。因为<br>对于这个问题没有可用的基准，我们建议如何为基于DDD17事件的部分序列生成自动但近似的语义分段标记数据集。我们的评估显示了这种方法如何允许<br>有效的学习语义分割模型事件数据。为了给模型提供信息，我们还提出了一个新颖的事件相机数据表示，对两者都进行编码事件直方图及其时间分布。我们的se语义分割实验，比较了不同的代表表示，表明我们的方法允许有效的学习语义分割模型，我们的ap方法优于其他以前使用的事件表示，即使在不同的时间间隔进行评估。我们还要比较仅从事件实现的分割数据从传统图像分割，显示他们的优点，他们的缺点和com的好处结合这两个传感器的任务。为今后的工作，其中之一主要的挑战仍然是获得和产生更多的和更好的语义分割标签，通过替代做主要适应方法和/或事件相机模拟器(他们目前不提供这种标签)。</p>
<h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>作者要感谢NVIDIA公司。感谢您捐赠用于这项工作的Titan Xp GPU。这研究得到了西班牙政府项目DPI2015-69376-R和DPI2016-76676-RAEI/ federal - ue和阿拉贡地区政府(DGA)的部分资助T45 17 r /工程师协会)。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.chitose.cn">Chitose</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.chitose.cn/EVSegNet-paper/">https://www.chitose.cn/EVSegNet-paper/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.chitose.cn" target="_blank">Chitose-Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_2.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/rcnnfaster-paper/" title="rcnnfaster-paper"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_7.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">rcnnfaster-paper</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Face.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Chitose</div><div class="author-info__description">Hahaha</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/chitose-r"><i class="fab fa-github"></i><span>🛴/前往小家..</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/chitose-r" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:171450290@qq.com" target="_blank" title="Email"><i class="fa-solid fa-square-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="/qq/" target="_blank" title="QQ"><i class="fab fa-qq" style="color: #12b7f5;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#EV-SegNet-Semantic-Segmentation-for-Event-based-Cameras"><span class="toc-text">EV-SegNet: Semantic Segmentation for Event-based Cameras</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#EV-SegNet-%E5%9F%BA%E4%BA%8E%E4%BA%8B%E4%BB%B6%E7%9B%B8%E6%9C%BA%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-text">EV-SegNet:基于事件相机的语义分割</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#29-November-2018"><span class="toc-text">29 November, 2018</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%A5%E5%85%85%E6%9D%90%E6%96%99"><span class="toc-text">补充材料</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-text">1 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-text">2 相关工作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E4%BA%8B%E4%BB%B6%E7%9B%B8%E6%9C%BA%E5%BA%94%E7%94%A8"><span class="toc-text">2.1 事件相机应用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-text">2.2 语义分割</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E4%BB%8E%E4%BA%8B%E4%BB%B6%E5%88%B0%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-text">3 从事件到语义分割</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E4%BA%8B%E4%BB%B6%E6%95%B0%E6%8D%AE"><span class="toc-text">3.1 事件数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E4%BA%8B%E4%BB%B6%E8%A1%A8%E7%A4%BA"><span class="toc-text">3.2 事件表示</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E4%BA%8B%E4%BB%B6%E6%95%B0%E6%8D%AE%E7%9A%84%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-text">3.3 事件数据的语义分割</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Ev-Seg-%E4%BA%8B%E4%BB%B6%E5%88%86%E5%89%B2%E6%95%B0%E6%8D%AE"><span class="toc-text">4. Ev-Seg: 事件分割数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E5%AE%9E%E9%AA%8C%E9%AA%8C%E8%AF%81"><span class="toc-text">5 实验验证</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE%E5%92%8C%E5%BA%A6%E9%87%8F"><span class="toc-text">5.1 实验设置和度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2%E8%8A%82-%E4%BA%8B%E4%BB%B6%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-text">5.2节 事件语义分割</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E7%BB%93%E8%AE%BA%E4%B8%8E%E6%9C%AA%E6%9D%A5%E5%B7%A5%E4%BD%9C"><span class="toc-text">6 结论与未来工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%B4%E8%B0%A2"><span class="toc-text">致谢</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By Chitose</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script defer src="/js/cursor.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/Python/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🥩 Python (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/C/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🕶️ C (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/Embedded/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💳 Embedded (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/Pytorch/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📯 Pytorch (9)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/Paper/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📰 Paper (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/others/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🤡 others (11)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/Model/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🗞️ Model (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="https://www.chitose.cn/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" data-title="本站采用多线部署，主线路托管于Vercel" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=flat&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="https://dashboard.4everland.org/" style="margin-inline:5px" data-title="本站采用多线部署，备用线路托管于4EVERLAND" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-4EVERLAND-22DDDD?style=flat&amp;logo=IPFS" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var qweather_key = '6be604177b8a4c3e97c78a352ee324f7';
  var gaud_map_key = '17b299fafade134736e6a1d4acb5ef18';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '113.34532,23.15624';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023-12-17-2/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_1.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023-12-17-2/" alt="">第二篇文章</a><div class="blog-slider__text">这是第二篇文章</div><a class="blog-slider__button" href="2023-12-17-2/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Pytorch-6/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_10.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-19</span><a class="blog-slider__title" href="Pytorch-6/" alt="">Pytorch(6)-张量可微性</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="Pytorch-6/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023-12-17-3/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_3.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023-12-17-3/" alt="">第三篇文章</a><div class="blog-slider__text">这是第三篇文章</div><a class="blog-slider__button" href="2023-12-17-3/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false});</script></body></html>