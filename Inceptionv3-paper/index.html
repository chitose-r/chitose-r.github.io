<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Inceptionv3-paper | Chitose-Blog</title><meta name="author" content="Chitose"><meta name="copyright" content="Chitose"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="《Rethinking the Inception Architecture for Computer Vision》  重新思考计算机视觉的Inception体系结构 2015  摘要 对许多任务而言，卷积网络是目前最新的计算机视觉解决方案的核心。从2014年开始，深度卷积网络开始变成主流，在各种基准数据集上都取得了实质性成果。对于大多数任务而言，虽然增加的模型大小和计算成本都趋向">
<meta property="og:type" content="article">
<meta property="og:title" content="Inceptionv3-paper">
<meta property="og:url" content="https://www.chitose.cn/Inceptionv3-paper/index.html">
<meta property="og:site_name" content="Chitose-Blog">
<meta property="og:description" content="《Rethinking the Inception Architecture for Computer Vision》  重新思考计算机视觉的Inception体系结构 2015  摘要 对许多任务而言，卷积网络是目前最新的计算机视觉解决方案的核心。从2014年开始，深度卷积网络开始变成主流，在各种基准数据集上都取得了实质性成果。对于大多数任务而言，虽然增加的模型大小和计算成本都趋向">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_7.png">
<meta property="article:published_time" content="2024-02-06T00:54:31.000Z">
<meta property="article:modified_time" content="2024-02-06T00:54:31.000Z">
<meta property="article:author" content="Chitose">
<meta property="article:tag" content="演示">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_7.png"><link rel="shortcut icon" href="https://www.fomal.cc/favicon.ico"><link rel="canonical" href="https://www.chitose.cn/Inceptionv3-paper/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Inceptionv3-paper',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-06 08:54:31'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://www.fomal.cc/static/css/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Face.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">70</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/todolist/"><i class="fa-fw fas fa-link"></i><span> 计划</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_7.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Chitose-Blog"><span class="site-name">Chitose-Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/todolist/"><i class="fa-fw fas fa-link"></i><span> 计划</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Inceptionv3-paper</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-06T00:54:31.000Z" title="发表于 2024-02-06 08:54:31">2024-02-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-06T00:54:31.000Z" title="更新于 2024-02-06 08:54:31">2024-02-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">12.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>39分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Inceptionv3-paper"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1
id="rethinking-the-inception-architecture-for-computer-vision">《<strong>Rethinking
the Inception Architecture for Computer Vision</strong>》</h1>
<blockquote>
<h1
id="重新思考计算机视觉的inception体系结构-2015">重新思考计算机视觉的Inception体系结构
2015</h1>
</blockquote>
<h2 id="摘要"><strong>摘要</strong></h2>
<p>对许多任务而言，卷积网络是目前最新的计算机视觉解决方案的核心。从2014年开始，<strong>深度卷积网络开始变成主流</strong>，在各种<strong>基准数据集</strong>上都取得了实质性成果。对于大多数任务而言，虽然增加的模型大小和计算成本都趋向于转化为直接的质量收益（只要提供足够的标注数据去训练），但<strong>计算效率和低参数计数</strong>仍是各种应用场景的限制因素，例如移动视觉和大数据场景。目前，我们正在探索增大网络的方法，目标是通过适当的<strong>分解卷积</strong>和积极的<strong>正则化</strong>来尽可能地有效利用增加的计算。我们在ILSVRC
2012分类挑战赛的验证集上评估了我们的方法，结果证明我们的方法超过了目前最先进的方法并取得了实质性收益：对于<strong>单一框架(只看全图)</strong>评估错误率为：21.2%
top-1和5.6%
top-5，使用的网络计算代价为每次推断需要进行50亿次乘加运算并使用不到2500万的参数。通过四个模型组合和多次评估，我们报告了3.5%
top-5和17.3% top-1的错误率。 &gt;### 主要内容 &gt;
&gt;<strong>背景：</strong>自2014年开始，网络变得又大又深，计算复杂度高，无法在移动场景(边缘计算)和大数据场景下使用。
&gt; &gt;- VGG（深）和GoogleNet（宽） &gt;
&gt;<strong>目的：</strong>在加宽和加深网络的同时，我们要考虑计算的效率
&gt;
&gt;<strong>引出本文主旨：</strong>探索了<u>可分离卷积</u>和<u>正则化</u>去提高计算效率</p>
<h2 id="介绍">1 介绍</h2>
<p>从2012年Krizhevsky等人[9]赢得了ImageNet竞赛[16]起，他们的网络“AlexNet”已经成功了应用到了许多计算机视觉任务中，例如目标检测[5]，分割[12]，行人姿势评估[22]，视频分类[8]，目标跟踪[23]和超分辨率[3]。</p>
<p>这些成功推动了一个新研究领域，这个领域主要专注于<strong>寻找更高效运行的卷积神经网络</strong>。从2014年开始，通过利用<strong>更深(层数)更宽(神经元/参数量)</strong>的网络，网络架构的质量得到了明显改善。VGGNet[18]和GoogLeNet[20]在2014
ILSVRC
[16]分类挑战上取得了类似的高性能。<strong>一个有趣的发现是在分类性能上的收益趋向于转换成各种应用领域上的显著质量收益。</strong>这意味着深度卷积架构上的架构改进可以用来改善大多数越来越多地依赖于高质量、可学习视觉特征的其它计算机视觉任务的性能。网络质量的改善也导致了卷积网络在新领域的应用，在AlexNet特征不能与手工精心设计的解决方案竞争的情况下，例如，检测时的候选区域生成[4]。</p>
<p>尽管VGGNet[18]具有架构简洁的强有力特性，但它的成本很高：评估网络需要大量的计算。另一方面，GoogLeNet[20]的Inception架构也被设计为在内存和计算预算严格限制的情况下也能表现良好。例如，<strong>GoogleNet只使用了500万参数，与其前身AlexNet相比减少了12倍，AlexNet使用了6000万参数。此外，VGGNet使用了比AlexNet大约多3倍的参数。</strong></p>
<p>Inception的计算成本也远低于VGGNet或其更高性能的后继者[6]。这使得可以在大数据场景中[17]，[13]，在大量数据需要以合理成本处理的情况下或在内存或计算能力固有地受限情况下，利用Inception网络变得可行，例如在移动视觉设定中。通过应用<strong>针对内存使用的专门解决方案</strong>[2]，[15]或<strong>通过计算技巧优化某些操作的执行[10]，可以减轻部分这些问题。但是这些方法增加了额外的复杂性</strong>。此外，这些方法也可以应用于优化Inception架构，再次扩大效率差距。</p>
<p>然而，Inception架构的复杂性使得更难以对网络进行更改。如果单纯地放大架构，大部分的计算收益可能会立即丢失。此外，[20]并没有提供关于导致GoogLeNet架构的各种设计决策的贡献因素的明确描述。这使得它更难以在适应新用例的同时保持其效率。例如，如果认为有必要增加一些Inception模型的能力，<strong>将滤波器组大小的数量加倍的简单变换将导致计算成本和参数数量增加4倍。这在许多实际情况下可能会被证明是禁止或不合理的</strong>，尤其是在相关收益适中的情况下。在本文中，我们从描述一些<strong>一般原则和优化思想</strong>开始，对于以有效的方式扩展卷积网络来说，这被证实是有用的。虽然我们的原则不局限于Inception类型的网络，但是在这种情况下，它们更容易观察，因为Inception类型构建块的通用结构足够灵活，可以自然地合并这些约束。这通过大量使用降维和Inception模块的并行结构来实现，这允许减轻结构变化对邻近组件的影响。但是，对于这样做需要谨慎，因为应该遵守一些指导原则来保持模型的高质量。
&gt;### 主要内容 &gt;
&gt;（1）深度卷积网络性能的提升可以应用在其它计算机视觉任务中，这些任务有着共同点：它们都依赖学习到的高质量视觉特征（visual
features）。 &gt;
&gt;（2）卷积网络性能的提升会产生新的应用领域，比如AlexNet features
无法与手工工程相比，比如目标检测中候选框的生成。 &gt;
&gt;（3）在参数上对比其他模型展现GoogLeNet的优势(参数量Alexnet：6000W，GoogLeNet：500W，VGG16：1.3E)
&gt;
&gt;（4）一味的堆叠Inception模块将使得计算量爆炸，换来的精准度并不划算。
&gt;
&gt;这篇论文中，先会介绍通用设计原则和一些优化的思想，然后再探索新的Inception结构
&gt;</p>
<h2 id="通用的设计原则">2 通用的设计原则</h2>
<p>这里我们将介绍一些具有卷积网络的、具有各种架构选择的、基于大规模实验的设计原则。在这一点上，以下原则的效用是推测性的，另外将来的实验证据将对于评估其准确性和有效领域是必要的。然而，严重偏移这些原则往往会导致网络质量的恶化，修正检测到的这些偏差状况通常会导致改进的架构。</p>
<p>1.<strong>避免表征瓶颈，尤其是在网络的前面。</strong>前馈网络可以由从输入层到分类器或回归器的非循环图表示。这为信息流定义了一个明确的方向。对于分离输入输出的任何切口，可以访问通过切口的信息量。应该避免极端压缩的瓶颈。一般来说，在达到用于着手任务的最终表示之前，表示大小应该从输入到输出缓慢减小。理论上，信息内容不能仅通过表示的维度来评估，因为它丢弃了诸如相关结构的重要因素；维度仅提供信息内容的粗略估计。</p>
<ul>
<li>降维会造成各通道之间的相关性信息丢失，仅反应了致密的嵌入信息。（高维的稀疏特征-&gt;低维的稠密特征）</li>
</ul>
<p>2.<strong>更高维度的表示在网络中更容易局部处理。</strong>在卷积网络中增加每个图块的激活允许更多解耦的特征。所产生的网络将训练更快。</p>
<ul>
<li>相互独立的稀疏特征（猫脸、猫尾、猫牙...）</li>
</ul>
<p>3.<strong>空间聚合可以在较低维度嵌入上完成，而不会在表示能力上造成许多或任何损失。</strong>例如，在执行更多展开（例如3×3）卷积之前，可以在空间聚合之前减小输入表示的维度，没有预期的严重不利影响。我们假设，如果在空间聚合上下文中使用输出，则相邻单元之间的强相关性会导致维度缩减期间的信息损失少得多。鉴于这些信号应该易于压缩，因此尺寸减小甚至会促进更快的学习。</p>
<ul>
<li>3x3or5x5大卷积核卷积之前用1x1的卷积降维，
不会造成表示能力的丢失。</li>
</ul>
<p>4.<strong>平衡网络的宽度和深度。</strong>通过平衡每个阶段的滤波器数量和网络的深度可以达到网络的最佳性能。增加网络的宽度和深度可以有助于更高质量的网络。然而，如果两者并行增加，则可以达到恒定计算量的最佳改进。因此，计算预算应该在网络的深度和宽度之间以平衡方式进行分配。</p>
<p>虽然这些原则可能是有意义的，但并不是开箱即用的直接使用它们来提高网络质量。我们的想法是仅在不明确的情况下才明智地使用它们。
&gt;这一章主要是介绍了作者想到的四种设计原则，论文中说道，这几种设计原则虽然没有严格的证明或者实验加持，但你要大致上遵守，如果你背离这几个原则太多，则必然会造成较差的实验结果。
&gt; &gt;####
原则一：要避免过度的降维和压缩特征导致特征表达瓶颈，特别是在网络的浅层。
&gt; &gt;<strong>做法：</strong>feature map
长宽大小应随网络加深缓慢减小（不能猛减）。 &gt;
&gt;<strong>原因：</strong>过度的降维或者收缩特征将造成一定程度的信息丢失（信息相关性丢失）
&gt; &gt;&gt;<strong>为何特别是网络的浅层？</strong> &gt;&gt;
&gt;&gt;因为在网络的浅层丢失的原图信息还不是很多，仍然保留信息的稀疏性。如果在浅层就进行过度地压缩和降维，会对后面提取特征等工作是有负面影响的。
&gt; &gt;#### 原则二：特征（神经元数量）越多，收敛越快 &gt;
&gt;<strong>理解：</strong>这里的特征多不是说特征图像多，而是说相互独立的特征多，特征分解的彻底。
&gt;
&gt;<strong>举例：</strong>人脸特征分解成人脸、人左眼、人右眼、鼻子、嘴巴、眉毛等等独立特征会比单纯的一张大脸特征收敛的快。（赫布原理）
&gt; &gt;####
原则三：大卷积核的卷积之前可以先降维，这个操作并不会造成太多的损失。
&gt;
&gt;<strong>空间聚合</strong>：即通过聚集相邻特征的信息来降低输入数据的维度，同时尽量保持表示能力不受损失。
&gt; &gt;<strong>原因：</strong>InceptionV1中使用的模块里有
3×3和5×5的卷积，并且在他们之前有使用1×1的卷积，这样的降维操作对于邻近单元的强相关性中损失的特征信息很少。
&gt; &gt;<strong>举例：</strong>每一层输出的feature
map上每一个相邻的像素，它们的感受野是相邻且有一部分是重合的，即它们高度相关；若将它们进行1x1卷积后，特征信息是可以得到保证，因为1x1卷积后的feature
map是能够实现跨通道的信息交融。 &gt; &gt;####
原则四：均衡网络中的深度和宽度。 &gt; &gt;-
深度就是指层数的多少，宽度指每一层中卷积核的个数，也就是提取到的特征数。
&gt;- 让深度和宽度并行提升，成比例的提升，能提高性能和计算效率。 &gt;-
可以让计算量在每一层上均匀分配，VGG那第一层全连接层的数据堆积就属于不均匀分配的情况。
&gt;
&gt;&gt;举例：输入特征是10x6x6，卷积层是in=10,out=4,size=2的卷积核，输出层是4x5x5
&gt;&gt;
&gt;&gt;过程：存在4个10x2x2的卷积核，对于每个卷积核：生成1个5x5的map（10个5x5的map按位求和）。
&gt;&gt; &gt;&gt;每个位置的参数都不一样。 &gt; &gt;#### 总结 &gt; &gt;-
渐进降维 &gt;- 丰富特征：参数量多（宽度多） &gt;-
智能降维：大卷积核前用1x1卷积核进行降维，可以减少计算量而不会对特征表达能力造成太大损失。
&gt;- 深宽同步</p>
<h2 id="分解大卷积核">3 分解大卷积核</h2>
<p>​
GoogLeNet网络[20]的大部分<strong>初始收益来源于大量地使用降维</strong>。这可以被视为以计算有效的方式分解卷积的特例。考虑例如1×1卷积层之后接一个3×3卷积层的情况。在视觉网络中，预期相近激活的输出是高度相关的。因此，我们可以预期，它们的激活可以在聚合之前被减少，并且这应该会导致类似的富有表现力的局部表示。</p>
<p>  在这里，我们将在各种设定中探索卷积分解的其它方法，特别是为了提高解决方案的计算效率。由于Inception网络是全卷积的，每个权重对应每个激活的一次乘法。因此，任何计算成本的降低会导致参数数量减少。这意味着，通过适当的分解，我们可以得到更多的解耦参数，从而加快训练。此外，我们可以使用计算和内存节省来增加我们网络的滤波器组的大小，同时保持我们在单个计算机上训练每个模型副本的能力。</p>
<blockquote>
<h3 id="启发">启发</h3>
<p>Googlenet的inception成功原因大部分得益于使用1 ×1 的卷积核，1 ×1
卷积核可以看作一个特殊的大卷积核分解过程，它通过降维大大降低计算量，增加非线性，跨通道交流造成损失少。</p>
<h3 id="原因">原因</h3>
<p>由上面的原则三，在使用大卷积核之前先用1 × 1卷积核，feature
map信息不会丢失很多，因为感受野相邻的元素相关性很强，他们在卷积的过程中重合度很高，仅相差一个步长，所以feature
map基本上不会丢失特征信息(元素特征相关性不变)。</p>
<h3 id="探究方法">探究方法</h3>
<p>在这篇文章中，作者探究了不同设置下的分解卷积。通过分解卷积在减少参数数量的同时可以得到更多的解耦特征，加快网络的训练。同时，节省下来的空间、计算资源可以用于进一步增加卷积核的尺寸，以达到代价基本不变下的更高性能。</p>
<blockquote>
<h4 id="激活">激活：</h4>
<p>神经元（像素）；</p>
<h4 id="聚合">聚合：</h4>
<p>3x3卷积</p>
<h4 id="x1卷积核的作用">1x1卷积核的作用：</h4>
<p>降维度、降参数、跨通道融合、增加非线性。</p>
<h4 id="解耦">解耦：</h4>
<p>将复杂的操作或模型参数分解为更简单、更小的部分。即在3x3卷积前使用1x1（原则三）可增加滤波器组的大小（卷积核的数量）</p>
<h3 id="卷积分解的例子inception模块">卷积分解的例子：Inception模块</h3>
<p>假设你有一个使用标准卷积操作的CNN，其中一个卷积层使用了较大的卷积核，比如5x5。这个5x5的卷积核作用在输入特征图上，每个权重与输入特征图的激活相乘，然后求和得到输出特征图的一个像素点。</p>
<h4 id="未分解的卷积操作">未分解的卷积操作</h4>
<ul>
<li>假设输入特征图有64个通道，你想使用5x5的卷积核生成256个通道的输出特征图。</li>
<li>参数量 = (5 * 5 * 64 + 1) * 256 = 102,656个参数</li>
</ul>
<h4 id="分解卷积操作">分解卷积操作</h4>
<ol type="1">
<li><strong>第一步：使用1x1的卷积核降维</strong>。假设你首先用1x1的卷积核将输入的64个通道降维到16个通道。</li>
</ol>
<ul>
<li>参数量 = (1 * 1 * 64 + 1) * 16 = 1,040个参数</li>
</ul>
<ol start="2" type="1">
<li><strong>第二步：在降维后的特征图上应用3x3的卷积核</strong>。然后，对这16个通道的特征图应用3x3的卷积核，以生成最终的256个通道的输出特征图。</li>
</ol>
<ul>
<li>参数量 = (3 * 3 * 16 + 1) * 256 = 37,120个参数</li>
</ul>
<p>通过这种分解，总的参数量变为1,040 + 37,120 =
38,160个参数，远少于未分解前的102,656个参数。</p>
</blockquote>
</blockquote>
<h3 id="分解成更小的卷积">3.1 分解成更小的卷积</h3>
<p>​
具有较大空间滤波器（例如5×5或7×7）的卷积在计算方面往往不成比例地昂贵。例如，具有n个滤波器的5×5卷积在具有m个滤波器的网格上比具有相同数量的滤波器的3×3卷积的计算量高25/9=2.78倍。<strong>当然，5×5滤波器在更前面的层可以捕获更远的单元激活之间、信号之间的依赖关系，因此滤波器几何尺寸的减小带来了很大的表现力损失。</strong>然而，我们可以询问5×5卷积是否可以被具有相同输入尺寸和输出深度的参数较小的多层网络所取代。如果我们放大5×5卷积的计算图，我们看到每个输出看起来像一个小的完全连接的网络，在其输入上滑过5×5的块（见图1）。由于我们正在构建视觉网络，所以通过两层的卷积结构再次利用平移不变性来代替全连接的组件似乎是很自然的：第一层是3×3卷积，第二层是在第一层的3×3输出网格之上的一个全连接层（见图1）。通过在输入激活网格上滑动这个小网络，用两层3×3卷积来替换5×5卷积（比较图4和5）。
​
该设定通过相邻块之间共享权重明显减少了参数数量。为了分析预期的计算成本节省，我们将对典型的情况进行一些简单的假设：我们可以假设n=αm，也就是我们想通过常数α因子来改变激活/单元的数量。由于5×5卷积是聚合的，α通常比1略大（在GoogLeNet中大约是1.5）。用两个层替换5×5层，似乎可以通过两个步骤来实现扩展：在两个步骤中通过√α增加滤波器数量。为了简化我们的估计，通过选择α=1（无扩展），如果我们单纯地滑动网络而不重新使用相邻网格图块之间的计算，我们将增加计算成本。滑动该网络可以由两个3×3的卷积层表示，其重用相邻图块之间的激活。<strong>这样，我们最终得到一个计算量减少到(9+9)/25的网络，通过这种分解导致了28％的相对增益。</strong>每个参数在每个单元的激活计算中只使用一次，所以参数计数具有完全相同的节约。不过，这个设置提出了两个一般性的问题：<strong>这种替换是否会导致任何表征力的丧失？</strong>如果我们的主要目标是对计算的线性部分进行分解，<strong>是不是建议在第一层保持线性激活？</strong>我们已经进行了几个控制实验（例如参见图2），并且在分解的所有阶段中使用线性激活总是逊于使用修正线性单元。我们将这个收益归因于网络可以学习的增强的空间变化，特别是如果我们对输出激活进行批标准化[7]。当对维度减小组件使用线性激活时，可以看到类似的效果。
​图2。两个Inception模型间几个控制实验中的一个，其中一个分解为线性层+
ReLU层，另一个使用两个ReLU层。在三亿八千六百万次运算后，在验证集上前者达到了76.2%
top-1准确率，后者达到了77.2% top-1的准确率。</p>
<blockquote>
<h3 id="方法">方法</h3>
<p>将一个5×5的卷积换成两个3×3卷积，同理7×7卷积可以用3个3×3卷积。（大大减少参数数量，感受野不变）</p>
<h3 id="结果">结果</h3>
<p>相同卷积核个数核feature map尺寸的情况下，5 × 5 卷积核比3
×3卷积核计算量高了2.78倍。</p>
<ul>
<li>假设输入和输出的尺寸不变的情况下</li>
</ul>
<h3 id="原因-1">原因</h3>
<p>相邻感受野的权值共享（共享卷积核，即卷积核内的数值都是一样的，用同一个卷积核），所以减少了很多计算量。</p>
<blockquote>
<p><strong>问题一：这种替代会影响网络的表达能力吗？</strong></p>
</blockquote>
<blockquote>
<p>直观的看是可行的，从结果看也是可行的。但是要问严谨的数学原理，确实难以解释。</p>
</blockquote>
<blockquote>
<p><strong>问题二：如果我们的目标是分解计算的线性部分，是否会建议保留第一层的线性激活性？</strong></p>
</blockquote>
<blockquote>
<p>对于分解后的激活函数，作者通过实验证明，保留对于原图的第一次3
×3卷积的激活函数有较好效果（一层卷积变成两层了，增加了非线性变换，增强模型非线性表达能力），用BN后效果更好。</p>
</blockquote>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure1.png" /></p>
<blockquote>
<p>图1。迷你网络取代了5x5卷积</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure2.png" /></p>
<blockquote>
<p>图2。两个Inception模型之间的几个控制实验之一，其中一个使用因子分解为线性+ReLU层，另一个使用两个ReLU层。在386万次运行后，前者稳定在76.2%，而后者达到77.2%验证集中排名前1的准确性。</p>
</blockquote>
<h3 id="非对称分解卷积">3.2 非对称分解卷积</h3>
<p>上述结果表明，大于3×3的卷积滤波器可能不是通常有用的，因为它们总是可以简化为3×3卷积层序列。我们仍然可以问这个问题，是否应该把它们分解成更小的，例如2×2的卷积。然而，<strong>通过使用非对称卷积，可以做出甚至比2×2更好的效果，即n×1。</strong>例如使用3×1卷积后接一个1×3卷积，相当于以与3×3卷积相同的感受野滑动两层网络（参见图3）。如果输入和输出滤波器的数量相等，那么对于相同数量的输出滤波器，两层解决方案节省33％。相比之下，将3×3卷积分解为两个2×2卷积表示仅节省了11％的计算量。</p>
<p>在理论上，我们可以进一步论证，<strong>可以通过1×n卷积和后面接一个n×1卷积替换任何n×n卷积，并且随着n增长，计算成本节省显著增加</strong>（见图6）。实际上，我们发现，采用这种分解在前面的层次上不能很好地工作，但是<strong>对于中等网格尺寸（在m×m特征图上，其中m范围在12到20之间），其给出了非常好的结果。</strong>在这个水平上，通过使用1×7卷积，然后是7×1卷积可以获得非常好的结果。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure3.png" /></p>
<blockquote>
<p>图3。取代3×3卷积的迷你网络。这个该网络的下层由3×1卷积和3输出单位。</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure4.png" /></p>
<blockquote>
<p>图4。原来的Inception模型所述。</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure5.png" /></p>
<blockquote>
<p>图5。Inception模型，其中每个5×5卷积被两个3×3卷积重新放置，如的原理3所建议的第2节。</p>
</blockquote>
<blockquote>
<h3 id="方法-1">方法：</h3>
<p>将3x3卷积可分解为1x3和3x1两个不对称卷积（空间可分离卷积）----宽度上的分解</p>
<p>假设原始为3×3的图，使用3× 1的卷积核去卷积，得到一个feature
map，然后再用1× 3的卷积核对刚才得到的feature map做卷积得到1×1的feature
map（相当于全连接层）。</p>
<h3 id="结果-1">结果：</h3>
<p>在输入和输出等同的情况下，参数降低33%（将3x3卷积核分解为两个2x2卷积核，只是降低了11%）</p>
<ul>
<li>公式如下，n为卷积核尺寸</li>
</ul>
<p><span class="math display">\[
\frac{n^2 - 2n}{n^2}
\]</span></p>
<h3 id="结论">结论：</h3>
<p>（1）这种分解 (n ×n 分解成了 n×1 和1 ×n) ，n
越大节省的运算量越大。</p>
<p>（2）这种分解在前面的层效果不好，使用feature map大小在12-20之间。</p>
<h3 id="变种">变种：</h3>
<p>可以理解成不对称卷积是在深度上分解。而扩展滤波器组是在宽度上分解，应用在最后的输出分类层之前，用该模块扩展特征维度生成高维稀疏特征（增加特征个数，符合原则二）。</p>
</blockquote>
<h2 id="辅助分类器">4 <strong>辅助分类器</strong></h2>
<p>[20]引入了辅助分类器的概念，以改善非常深的网络的收敛。<strong>最初的动机是将有用的梯度推向较低层，使其立即有用，并通过抵抗非常深的网络中的消失梯度问题来提高训练过程中的收敛。</strong>Lee等人[11]也认为辅助分类器促进了更稳定的学习和更好的收敛。有趣的是，我们发现辅助分类器在训练早期并没有导致改善收敛：在两个模型达到高精度之前，有无侧边网络的训练进度看起来几乎相同。接近训练结束，辅助分支网络开始超越没有任何分支的网络的准确性，达到了更高的稳定水平。</p>
<p>另外，[20]在网络的不同阶段使用了两个侧分支。<strong>移除更下面的辅助分支对网络的最终质量没有任何不利影响。</strong>再加上前一段的观察结果，这意味着[20]最初的假设，<strong>这些分支有助于演变低级特征很可能是不适当的。</strong>相反，我们认为辅助分类器起着正则化项的作用。事实证明了这一点如果辅助分类器被批量归一化[7]或具有丢弃层。这也为这个猜想提供了一个弱的支持性证据该批处理规范化充当正则化子。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure6.png" /></p>
<blockquote>
<p>图6。n×n卷积分解后的Inception模块。在我们提出的架构中，对17×17的网格我们选择n=7。（滤波器尺寸可以通过原则3选择）</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure7.png" /></p>
<blockquote>
<p>图7：具有扩展滤波器组输出的Inception模块。此架构用于最粗糙的（8×8）网格，以促进高维表征，正如第2节的第二原则所建议的。我们仅在最粗糙的网格上使用此解决方案，因为在这一层产生高维稀疏表征最为关键，相比于空间聚合，局部处理（通过1×1卷积）的比例增加了。</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure8.png" /></p>
<blockquote>
<p>图8：最后一个17×17层顶部的辅助分类器。侧头部中层的批量归一化[7]在top-1准确率上带来了0.4%的绝对增益。下轴显示了执行的迭代次数，每次迭代的批量大小为32。</p>
</blockquote>
<blockquote>
<h3 id="较之前的改进">较之前的改进</h3>
<p>在GoogLeNet里面用了两个辅助分类器（4a和4b两个模块后面），但是事后实验证明，辅助分类器并未在训练初期改善收敛性，第一个没什么用，在v2，v3里面去掉了。</p>
</blockquote>
<h2 id="高效下降特征图尺寸">5 高效下降特征图尺寸</h2>
<p>传统上，卷积网络使用一些池化操作来缩减特征图的网格大小。<strong>为了避免表示瓶颈，在应用最大池化或平均池化之前，需要扩展网络滤波器的激活维度。</strong>例如，开始有一个带有k个滤波器的d×d网格，如果我们想要达到一个带有2k个滤波器的网格，我们首先需要用2k个滤波器计算步长为1的卷积，然后应用一个额外的池化步骤。这意味着总体计算成本由在较大的网格上使用次运算的昂贵卷积支配。一种可能性是转换为带有卷积的池化，因此导致次运算，将计算成本降低为原来的四分之一。然而，由于表示的整体维度下降到会导致表示能力较弱的网络（参见图9），这会产生一个表示瓶颈。<strong>我们建议另一种变体，其甚至进一步降低了计算成本，同时消除了表示瓶颈</strong>（见图10），而不是这样做。我们可以使用<strong>两个平行的步长为2的块：P和C。</strong>P是一个池化层（平均池化或最大池化）的激活，两者都是步长为2，其滤波器组连接如图10所示。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure9.png" /></p>
<blockquote>
<p>图9。减少网格尺寸的两种替代方式。左边的解决方案违反了表示瓶颈的原则1。右边的版本计算量昂贵3倍。</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Figure10.png" /></p>
<blockquote>
<p>图10。缩减网格尺寸的同时扩展滤波器组的Inception
模块。它不仅廉价并且避免了原则1中提出的表示瓶颈。右侧的图表示相同的解决方案，但是从网格大小而不是运算的角度来看。</p>
</blockquote>
<blockquote>
<h3 id="传统降维方法">传统降维方法</h3>
<p><strong>方法一：</strong>先对feature
map池化会导致表征瓶颈，信息量丢失很多；（<strong>池化-&gt;卷积</strong>）</p>
<p><strong>方法二：</strong>信息保留下了，但计算量比较大；
（<strong>卷积-&gt;池化</strong>）</p>
<ul>
<li>传统池化为降低宽度而定，而深宽同步，深度也要上去。上去的方法有两个：↑各有缺点。</li>
</ul>
<h3 id="计算量比较">计算量比较</h3>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-computevs.png" /></p>
<h3 id="文本改进">文本改进</h3>
<p>并行执行（卷积C+池化P），再进行feature map的堆叠。</p>
<p>inception并行模块结构图:
左边两路卷积，右边池化。最后再叠加，可以在不丢失信息的情况下减小参数量、升维、降宽。</p>
</blockquote>
<h2 id="inception-v2">6 Inception-v2</h2>
<p>在这里，我们连接上面的点，并提出了一个新的架构，在ILSVRC
2012分类基准数据集上提高了性能。我们的网络布局在表1中给出。注意，基于与3.1节中描述的同样想法，我们<strong>将传统的7×7卷积分解为3个3×3卷积</strong>。对于网络的Inception部分，我们在35×35处有3个传统的Inception模块，每个模块有288个滤波器。使用第5节中描述的网格缩减技术，这将缩减为17×17的网格，具有768个滤波器。这之后是图5所示的5个分解的Inception模块实例。使用图10所示的网格缩减技术，这被缩减为8×8×1280的网格。在最粗糙的8×8级别，我们有两个如图6所示的Inception模块，每个块连接的输出滤波器组的大小为2048。网络的详细结构，包括Inception模块内滤波器组的大小，在补充材料中给出，在提交的tar文件中的model.txt中给出。然而，我们已经观察到，只要遵守第2节的原则，对于各种变化网络的质量就相对稳定。虽然我们的网络深度是42层，但我们的计算成本仅比GoogLeNet高出约2.5倍，它仍比VGGNet要高效的多。</p>
<p>表1。提出的网络架构的轮廓。每个模块的输出大小是下一模块的输入大小。我们正在使用图10所示的缩减技术的变种，以缩减应用时Inception块间的网格大小。我们用0填充标记了卷积，用于保持网格大小。这些Inception模块内部也使用0填充，不会减小网格大小。所有其它层不使用填充。选择各种滤波器组大小来观察第2节的原理4。
图7。具有扩展的滤波器组输出的Inception模块。这种架构被用于最粗糙的（8×8）网格，以提升高维表示，如第2节原则2所建议的那样。我们仅在最粗的网格上使用了此解决方案，因为这是产生高维度的地方，稀疏表示是最重要的，因为与空间聚合相比，局部处理（1×1
卷积）的比率增加。</p>
<blockquote>
<p>作者基于以上的分析与所提出的通用性准则提出了改进后的Inception-v2架构：</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Table1.png" /></p>
<ul>
<li>figure5 ——把5×5卷积用两个3×3卷积代替</li>
<li>figure6 ——应用的那个不对称卷积</li>
<li>figure7 ——用在输出分类前的那个扩展滤波器组</li>
</ul>
<p>相比起Inception-v1结构，这里将开始的7x7卷积使用3个3x3卷积替代，在后面的Inception模块中分别使用了三种不同的模式：</p>
<ul>
<li>第一部分输入的特征图尺寸为35x35x288,采用了图5中的架构，将5x5以两个3x3代替。</li>
<li>第二部分输入特征图尺寸为17x17x768，采用了图6中nx1+1xn的结构</li>
<li>第三部分输入特征图尺寸为8x8x1280,
采用了图7中所示的并行模块的结构</li>
</ul>
<h3 id="结果-2">结果</h3>
<p>这个网络是符合上面说的设计的四大原则的，
网络有42层深，计算量是googlenet的2.5倍(仍比VGG高效)。</p>
</blockquote>
<h2 id="通过标签平滑进行模型正则化">7 通过标签平滑进行模型正则化</h2>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-7.png" /></p>
<blockquote>
<p>(这一节非常复杂，涉及大量公式，本人水平有限就不再推理，这里只解释相关概念和算法效果。相关计算推导推荐大家看b站同济子豪兄)</p>
<blockquote>
<p><strong>Q1：one-hot是什么？</strong></p>
<p>独热编码即 One-Hot
编码，又称一位有效编码，其方法是使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意时候，其中只有一位有效。（简单地说，就是对于多分类向量，计算机中往往用[0,
1, 3]等此类离散的、随机的而非有序(连续)的向量表示，而one-hot vector
对应的向量便可表示为[0, 1, 0]，即对于长度为n
的数组，只有一个元素是1，其余都为0。因此表征我们已知样本属于某一类别的概率是为1的确定事件，属于其他类别的概率则均为0。）</p>
<p><strong>Q2：one-hot缺点？</strong></p>
<p>1.过拟合：因为模型使得正确标签的分数足够大</p>
<p>2.降低模型的泛化能力，降低了网络的适应性</p>
<p><strong>Q3：LSR是什么？</strong></p>
<p>在深度学习样本训练的过程中，我们采用one-hot标签去进行计算交叉熵损失时，只考虑到训练样本中正确的标签位置（one-hot标签为1的位置）的损失，而忽略了错误标签位置（one-hot标签为0的位置）的损失。这样一来，模型可以在训练集上拟合的很好，但由于其他错误标签位置的损失没有计算，导致预测的时候，预测错误的概率增大。Label
Smoothing
Regularization（LSR）标签平滑正则化,机器学习中的一种正则化方法，是一种通过在输出y中添加噪声，实现对模型进行约束，降低模型过拟合（overfitting）程度的一种约束方法（regularization
methed）。</p>
<p><strong>Q4：LSR的实质？</strong></p>
<p>标签平滑的实质就是促使神经网络中进行softmax激活函数激活之后的分类概率结果向正确分类靠近，即正确的分类概率输出大（对应的one-hot标签为1位置的softmax概率大），并且同样尽可能的远离错误分类（对应的one-hot标签为0位置的softmax概率小），即错误的分类概率输出小。</p>
</blockquote>
<h3 id="label-smooth实现">Label Smooth实现</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">new_labels = (<span class="number">1.0</span> - label_smoothing) * one_hot_labels + label_smoothing / （num_classes-<span class="number">1</span>）</span><br></pre></td></tr></table></figure>
<h4 id="参数">参数</h4>
<p>label_smoothing = 0.1</p>
<p>num_classes = 1000</p>
<h4 id="结果-3">结果</h4>
<p>Label
smooth提高了网络精度0.2%，在正确的答案上添加一点错误，担责写错误是可以相互抵消的，正确的就会凸显出来，不会出现过拟合。</p>
</blockquote>
<h2 id="training-methodology训练方法">8 Training
Methodology—训练方法</h2>
<p>我们在TensorFlow[1]分布式机器学习系统上使用<strong>随机梯度方法</strong>训练了我们的网络，使用了50个副本，每个副本在一个NVidia
Kepler
GPU上运行，<strong>bs为32</strong>，<strong>100个epoch</strong>。我们之前的实验使用动量方法[19]，<strong>衰减值为0.9</strong>，而我们最好的模型是用<strong>RMSProp</strong>
[21]实现的，<strong>衰减值为0.9，ϵ=1.0</strong>。我们使用<strong>0.045</strong>的学习率，<strong>每两个epoch以0.94的指数速率衰减</strong>。此外，<strong>阈值为2.0的梯度裁剪</strong>[14]被发现对于稳定训练是有用的。使用随时间计算的运行参数的平均值来执行模型评估。</p>
<blockquote>
<p>最优模型的优化方法：RMSProp + learning rate decay(0.9) ,
同时使用了阈值为2的梯度截断使得训练更加稳定。</p>
<h3 id="具体参数">具体参数</h3>
<table>
<thead>
<tr class="header">
<th>初始模型</th>
<th>tesnsorflow</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>优化器</td>
<td>stochastic gradient</td>
</tr>
<tr class="even">
<td>机器个数</td>
<td>50</td>
</tr>
<tr class="odd">
<td>batch size</td>
<td>32</td>
</tr>
<tr class="even">
<td>epoch</td>
<td>100</td>
</tr>
<tr class="odd">
<td>最好模型</td>
<td>RMSProp</td>
</tr>
<tr class="even">
<td>decay</td>
<td>0.9</td>
</tr>
<tr class="odd">
<td>初始学习率</td>
<td>0.045</td>
</tr>
<tr class="even">
<td>指数衰减</td>
<td>0.94</td>
</tr>
</tbody>
</table>
</blockquote>
<h2 id="小分辨率输入性能">9 小分辨率输入性能</h2>
<p>视觉网络的典型用例是用于检测的后期分类，例如在Multibox
[4]上下文中。这包括分析在某个上下文中包含单个对象的相对较小的图像块。任务是确定图像块的中心部分是否对应某个对象，如果是，则确定该对象的类别。这个挑战的是对象往往比较小，分辨率低。这就提出了如何正确处理低分辨率输入的问题。</p>
<p>普遍的看法是，使用更高分辨率感受野的模型倾向于导致显著改进的识别性能。然而，区分第一层感受野分辨率增加的效果和较大的模型容量、计算量的效果是很重要的。如果我们只是改变输入的分辨率而不进一步调整模型，那么我们最终将使用计算上更便宜的模型来解决更困难的任务。当然，由于减少了计算量，这些解决方案很自然就出来了。为了做出准确的评估，模型需要分析模糊的提示，以便能够“幻化”细节。这在计算上是昂贵的。因此问题依然存在：如果计算量保持不变，更高的输入分辨率会有多少帮助。确保不断努力的一个简单方法是在较低分辨率输入的情况下减少前两层的步长，或者简单地移除网络的第一个池化层。为了这个目的我们进行了以下三个实验：</p>
<p>1.步长为2，大小为299×299的感受野和最大池化。</p>
<p>2.步长为1，大小为151×151的感受野和最大池化。</p>
<p>3.步长为1，大小为79×79的感受野和第一层之后没有池化。</p>
<p>所有三个网络具有几乎相同的计算成本。虽然第三个网络稍微便宜一些，但是池化层的成本是无足轻重的（在总成本的1％以内）。在每种情况下，网络都进行了训练，直到收敛，并在ImageNet
ILSVRC
2012分类基准数据集的验证集上衡量其质量。结果如表2所示。虽然分辨率较低的网络需要更长时间去训练，但最终结果却与较高分辨率网络的质量相当接近。表2。当感受野尺寸变化时，识别性能的比较，但计算代价是不变的。但是，如果只是单纯地按照输入分辨率减少网络尺寸，那么网络的性能就会差得多。然而，这将是一个不公平的比较，因为我们将在比较困难的任务上比较一个便宜16倍的模型。表2的这些结果也表明，有人可能会考虑在R-CNN
[5]的上下文中对更小的对象使用专用的高成本低分辨率网络。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Table2.png" /></p>
<blockquote>

</blockquote>
<blockquote>
<h3 id="目标检测难点">目标检测难点：</h3>
<p>图像中低分辨率的目标难以检测，如何处理低分辨率的输入？</p>
<h3 id="常规方法">常规方法：</h3>
<p>对这些使用更大感受野来进行卷积，以提高在低分辨率输入上的识别准确率。</p>
<h3 id="不足">不足：</h3>
<p>这很难说明性能的提升是来自于感受野的扩大还是模型能力及计算量的增加。</p>
<h3 id="引出问题">引出问题：</h3>
<p>在保持计算代价不变的情况下，如何最大限度的提高分辨率？</p>
<h3 id="方法-2">方法：</h3>
<p>保持模型复杂度不变，降低前两层的步长，或者移除第一个池化层。</p>
<h3 id="实验验证">实验验证：</h3>
<p>三组实验感受野逐步下降而计算量保持不变：</p>
<p>（1）79x79的感受野，stride = 1，不进行maxpooling</p>
<p>（2）151x151的感受野，strde = 1，加上maxpooling</p>
<p>（3）299x299的感受野，stride = 2，加上maxpooling</p>
<p><strong>结论：</strong>实验表明虽然感受野增大，但是在保持计算量不变的情况下模型性能相差不大</p>
</blockquote>
<h2 id="实验结果和比较">10 实验结果和比较</h2>
<p>表3显示了我们提出的体系结构（Inception-v2）识别性能的实验结果，架构如第6节所述。每个Inception-v2行显示了累积变化的结果，包括突出显示的新修改加上所有先前修改的结果。标签平滑是指在第7节中描述的方法。分解的7×7包括将第一个7×7卷积层分解成3×3卷积层序列的改变。BN-auxiliary是指辅助分类器的全连接层也批标准化的版本，而不仅仅是卷积。<strong>我们将表3最后一行的模型称为Inception-v3，</strong>并在多裁剪图像和组合设置中评估其性能。我们所有的评估都在ILSVRC-2012验证集上的48238个非黑名单样本中完成，如[16]所示。我们也对所有50000个样本进行了评估，结果在top-5错误率中大约为0.1%，在top-1错误率中大约为0.2%。在本文即将出版的版本中，我们将在测试集上验证我们的组合结果，但是我们上一次对BN-Inception的春季测试[7]表明测试集和验证集错误趋于相关性很好。11.
结论我们提供了几个设计原则来扩展卷积网络，并在Inception体系结构的背景下进行研究。这个指导可以导致高性能的视觉网络，与更简单、更单一的体系结构相比，它具有相对适中的计算成本。Inception-v3的最高质量版本在ILSVR
2012分类上的单裁剪图像评估中达到了21.2％
的top-1错误率和5.6％的top-5错误率，达到了新的水平。与Ioffe等[7]中描述的网络相比，这是通过增加相对适中（2.5/times）的计算成本来实现的。尽管如此，我们的解决方案所使用的计算量比基于更密集网络公布的最佳结果要少得多：我们的模型比He等[6]的结果更好——将top-5(top-1)的错误率相对分别减少了25%
(14%)，然而在计算代价上便宜了六倍，并且使用了至少减少了五倍的参数（估计值）。我们的四个Inception-v3模型的组合效果达到了3.5％，多裁剪图像评估达到了3.5％的top-5的错误率，这相当于比最佳发布的结果减少了25％以上，几乎是ILSVRC
2014的冠军GoogLeNet组合错误率的一半。我们还表明，可以通过感受野分辨率为79×79的感受野取得高质量的结果。这可能证明在检测相对较小物体的系统中是有用的。我们已经研究了在神经网络中如何分解卷积和积极降维可以导致计算成本相对较低的网络，同时保持高质量。较低的参数数量、额外的正则化、批标准化的辅助分类器和标签平滑的组合允许在相对适中大小的训练集上训练高质量的网络。
<img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Table3.png" /></p>
<blockquote>
<p>表3：<strong>单次裁剪实验</strong>结果比较了各种贡献因素的累积效应。我们将我们的数据与Ioffe等人[7]发布的最佳单次裁剪推理结果进行了比较。对于“Inception-v2”行，更改是累积的，每个后续行除了前面的更改外，还包括新的更改。最后一行指的是所有的更改，这就是我们下面称为“Inception-v3”的内容。遗憾的是，He等人[6]仅报告了10次裁剪评估结果，而没有报告单次裁剪结果，这在下面的表4中有报告。</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Inv3-Table4.png" /></p>
<blockquote>
<p>表4：单模型，多裁剪实验结果比较了各种贡献因素的累积效应。我们将我们的数据与在ILSVRC
2012分类基准测试上发布的最佳单模型推理结果进行了比较。</p>
</blockquote>
<blockquote>
<h3 id="对inceptionv2-进行改进">对InceptionV2 进行改进：</h3>
<p>（1）InceptionV2 加入RMSProp(一种计算梯度的方法)</p>
<p>（2）在上面的基础上加入Label Smoothing(LSR,标签平滑正则化)</p>
<p>（3）在上面的基础上再加入7×7的卷积核分解(分解成3×3)</p>
<p>（4）在上面的基础上再加入含有BN的辅助分类器</p>
<p>所以本文最终提出的<strong>InceptionV3=inceptionV2+RMSProp优化+LSR+BN-auxilary</strong></p>
<p>同时也将Inception-v3进行了多尺度的训练，在单模型下的对比结果如下:
Table4</p>
<p>进一步地，Inception-v3进行模型融合（ensemble)后与其他模型做对比：Table2</p>
<p><strong>结论：</strong>可以看到Inception-v3在分类任务上都获得了更好的性能</p>
</blockquote>
<h2 id="结论-1">11 结论</h2>
<p>我们提供了几个设计原则来扩展卷积网络，并在Inception体系结构的背景下进行研究。这个指导可以导致高性能的视觉网络，与更简单、更单一的体系结构相比，它具有相对适中的计算成本。</p>
<p>Inception-v3的最高质量版本在ILSVR
2012分类上的单裁剪图像评估中达到了21.2％的top-1错误率和5.6％的top-5错误率，达到了新的水平。与Ioffe等[7]中描述的网络相比，这是通过增加相对适中（2.5/times）的计算成本来实现的。尽管如此，我们的解决方案所使用的计算量比基于更密集网络公布的最佳结果要少得多：我们的模型比He等[6]的结果更好——将top-5(top-1)的错误率相对分别减少了25%(14%)，然而在计算代价上便宜了六倍，并且使用了至少减少了五倍的参数（估计值）。我们的四个Inception-v3模型的组合效果达到了3.5％，多裁剪图像评估达到了3.5％的top-5的错误率，这相当于比最佳发布的结果减少了25％以上，几乎是ILSVRC
2014的冠军GoogLeNet组合错误率的一半。</p>
<p>我们还表明，可以通过感受野分辨率为79×79的感受野取得高质量的结果。这可能证明在检测相对较小物体的系统中是有用的。我们已经研究了在神经网络中如何分解卷积和积极降维可以导致计算成本相对较低的网络，同时保持高质量。较低的参数数量、额外的正则化、标准化的辅助分类器和标签平滑的组合允许在相对适中大小的训练集上训练高质量的网络。</p>
<blockquote>
<p>总结一句话：我们的模型很好！</p>
</blockquote>
<h2 id="总结">总结</h2>
<p><strong>Q1：论文试图解决什么问题？</strong></p>
<p>在加宽和加深网络的同时，探索了可分离卷积和正则化去提高计算效率，从而达到优化原有GooogLeNet模型，提高网络性能。</p>
<p><strong>Q2：这是否是一个新的问题？</strong></p>
<p>不是，是对原有InceptionV1的优化</p>
<p><strong>Q3：这篇文章要验证一个什么科学假设？</strong></p>
<p>探索了可分离卷积和正则化去提高计算效率</p>
<p><strong>Q4：有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</strong></p>
<p>无</p>
<p><strong>Q5：论文中提到的解决方案之关键是什么？</strong></p>
<p>1.卷积核分解：（1）将大的卷积核分解成小的（2）非对称分解</p>
<p>2.并行执行（卷积C+池化P），再进行feature map的堆叠</p>
<p>3.标签平滑（LSR）进行模型正则化</p>
<p>4.辅助分类器：在本文中，作者纠正了辅助分类器的作用，靠近输入辅助分类器（加不加没有影响），但是靠近输出的辅助分类器（加上BN后）可以起到正则化的作用。</p>
<p><strong>Q6：论文中的实验是如何设计的？</strong></p>
<p>在原有Inception-v2逐步改进，形成对照实验组，引出V3</p>
<p>Inception-v3进行了多尺度的训练，在单模型下的对比结果</p>
<p>Inception-v3进行模型融合（ensemble)后与其他模型做对比</p>
<p><strong>Q7：用于定量评估的数据集是什么？代码有没有开源？</strong></p>
<p>ImageNet2012，有开源</p>
<p><strong>Q8：论文中的实验及结果有没有很好地支持需要验证的科学假设？</strong></p>
<p>有，通过对照实验证明了结论</p>
<p><strong>Q9：这篇论文到底有什么贡献？</strong></p>
<p>改进原有的Inception-V1结构，使得CNN模型在分类任务上获得更高的性能
提出了四大设计原则 分解大filters，使其小型化、多层化，提出了“非对称卷积”
优化inception v1的auxiliary classifiers，并造了新的带BN的辅助分类器
演示了即使是低分辨率的输入也可以达到较好的识别效果 使用新的
inception并行模块解决了传统采样层的问题 inceptionV3 =
inceptionV2+RMSProp+LSR+BN-aux
<strong>Q10：下一步呢？有什么工作可以继续深入？</strong></p>
<p>如何在计算量不增加的情况下，解决由于信息压缩造成的信息损失问题。
如何在计算量不增加的情况下，增加模型的拓扑结构，以提高模型的表达能力。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.chitose.cn">Chitose</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.chitose.cn/Inceptionv3-paper/">https://www.chitose.cn/Inceptionv3-paper/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.chitose.cn" target="_blank">Chitose-Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_7.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/VGG-paper/" title="VGG-paper"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_8.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">VGG-paper</div></div></a></div><div class="next-post pull-right"><a href="/Inceptionv2-paper/" title="Inceptionv2-paper"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_3.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Inceptionv2-paper</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Face.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Chitose</div><div class="author-info__description">Hahaha</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">70</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/chitose-r"><i class="fab fa-github"></i><span>🛴/前往小家..</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/chitose-r" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:171450290@qq.com" target="_blank" title="Email"><i class="fa-solid fa-square-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="/qq/" target="_blank" title="QQ"><i class="fab fa-qq" style="color: #12b7f5;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#rethinking-the-inception-architecture-for-computer-vision"><span class="toc-text">《Rethinking
the Inception Architecture for Computer Vision》</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%87%8D%E6%96%B0%E6%80%9D%E8%80%83%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E7%9A%84inception%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84-2015"><span class="toc-text">重新思考计算机视觉的Inception体系结构
2015</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-text">1 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%9A%E7%94%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99"><span class="toc-text">2 通用的设计原则</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E8%A7%A3%E5%A4%A7%E5%8D%B7%E7%A7%AF%E6%A0%B8"><span class="toc-text">3 分解大卷积核</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%AF%E5%8F%91"><span class="toc-text">启发</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0"><span class="toc-text">原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A2%E7%A9%B6%E6%96%B9%E6%B3%95"><span class="toc-text">探究方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB"><span class="toc-text">激活：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%81%9A%E5%90%88"><span class="toc-text">聚合：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#x1%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-text">1x1卷积核的作用：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E8%80%A6"><span class="toc-text">解耦：</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%88%86%E8%A7%A3%E7%9A%84%E4%BE%8B%E5%AD%90inception%E6%A8%A1%E5%9D%97"><span class="toc-text">卷积分解的例子：Inception模块</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%AA%E5%88%86%E8%A7%A3%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C"><span class="toc-text">未分解的卷积操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E8%A7%A3%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C"><span class="toc-text">分解卷积操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E8%A7%A3%E6%88%90%E6%9B%B4%E5%B0%8F%E7%9A%84%E5%8D%B7%E7%A7%AF"><span class="toc-text">3.1 分解成更小的卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95"><span class="toc-text">方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-text">结果</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%9F%E5%9B%A0-1"><span class="toc-text">原因</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%88%86%E8%A7%A3%E5%8D%B7%E7%A7%AF"><span class="toc-text">3.2 非对称分解卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-1"><span class="toc-text">方法：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C-1"><span class="toc-text">结果：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-text">结论：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%98%E7%A7%8D"><span class="toc-text">变种：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BE%85%E5%8A%A9%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-text">4 辅助分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BE%83%E4%B9%8B%E5%89%8D%E7%9A%84%E6%94%B9%E8%BF%9B"><span class="toc-text">较之前的改进</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E6%95%88%E4%B8%8B%E9%99%8D%E7%89%B9%E5%BE%81%E5%9B%BE%E5%B0%BA%E5%AF%B8"><span class="toc-text">5 高效下降特征图尺寸</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95"><span class="toc-text">传统降维方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E9%87%8F%E6%AF%94%E8%BE%83"><span class="toc-text">计算量比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%87%E6%9C%AC%E6%94%B9%E8%BF%9B"><span class="toc-text">文本改进</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#inception-v2"><span class="toc-text">6 Inception-v2</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C-2"><span class="toc-text">结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%9A%E8%BF%87%E6%A0%87%E7%AD%BE%E5%B9%B3%E6%BB%91%E8%BF%9B%E8%A1%8C%E6%A8%A1%E5%9E%8B%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-text">7 通过标签平滑进行模型正则化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#label-smooth%E5%AE%9E%E7%8E%B0"><span class="toc-text">Label Smooth实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%82%E6%95%B0"><span class="toc-text">参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C-3"><span class="toc-text">结果</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#training-methodology%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95"><span class="toc-text">8 Training
Methodology—训练方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B7%E4%BD%93%E5%8F%82%E6%95%B0"><span class="toc-text">具体参数</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E5%88%86%E8%BE%A8%E7%8E%87%E8%BE%93%E5%85%A5%E6%80%A7%E8%83%BD"><span class="toc-text">9 小分辨率输入性能</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E9%9A%BE%E7%82%B9"><span class="toc-text">目标检测难点：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%84%E6%96%B9%E6%B3%95"><span class="toc-text">常规方法：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8D%E8%B6%B3"><span class="toc-text">不足：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BC%95%E5%87%BA%E9%97%AE%E9%A2%98"><span class="toc-text">引出问题：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95-2"><span class="toc-text">方法：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E9%AA%8C%E8%AF%81"><span class="toc-text">实验验证：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E5%92%8C%E6%AF%94%E8%BE%83"><span class="toc-text">10 实验结果和比较</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9inceptionv2-%E8%BF%9B%E8%A1%8C%E6%94%B9%E8%BF%9B"><span class="toc-text">对InceptionV2 进行改进：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA-1"><span class="toc-text">11 结论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By Chitose</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script defer src="/js/cursor.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" data-title="本站采用多线部署，主线路托管于Vercel" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=flat&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="https://dashboard.4everland.org/" style="margin-inline:5px" data-title="本站采用多线部署，备用线路托管于4EVERLAND" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-4EVERLAND-22DDDD?style=flat&amp;logo=IPFS" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var qweather_key = '6be604177b8a4c3e97c78a352ee324f7';
  var gaud_map_key = '17b299fafade134736e6a1d4acb5ef18';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '113.34532,23.15624';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023-12-17-2/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_7.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023-12-17-2/" alt="">第二篇文章</a><div class="blog-slider__text">这是第二篇文章</div><a class="blog-slider__button" href="2023-12-17-2/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Pytorch-6/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_8.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-19</span><a class="blog-slider__title" href="Pytorch-6/" alt="">Pytorch(6)-张量可微性</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="Pytorch-6/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023-12-17-3/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_10.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023-12-17-3/" alt="">第三篇文章</a><div class="blog-slider__text">这是第三篇文章</div><a class="blog-slider__button" href="2023-12-17-3/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false});</script></body></html>