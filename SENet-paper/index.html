<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>SENet-paper | Chitose-Blog</title><meta name="author" content="Chitose"><meta name="copyright" content="Chitose"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="Squeeze-and-Excitation Networks  挤压 - 激发网络&#x2F;SE网络  摘要 卷积神经网络建立在卷积操作的基础上，卷积操作通过融合空间和通道信息，从局部感受野中提取信息。为了增强网络的表征能力，许多现有工作都表明增强空间编码的好处。在这项工作中，我们专注于通道，并提出了一个新的架构单元，我们称之为“压缩-激励”（SE）块，它通过显式地模拟通道之间的相互依赖性，">
<meta property="og:type" content="article">
<meta property="og:title" content="SENet-paper">
<meta property="og:url" content="https://www.chitose.cn/SENet-paper/index.html">
<meta property="og:site_name" content="Chitose-Blog">
<meta property="og:description" content="Squeeze-and-Excitation Networks  挤压 - 激发网络&#x2F;SE网络  摘要 卷积神经网络建立在卷积操作的基础上，卷积操作通过融合空间和通道信息，从局部感受野中提取信息。为了增强网络的表征能力，许多现有工作都表明增强空间编码的好处。在这项工作中，我们专注于通道，并提出了一个新的架构单元，我们称之为“压缩-激励”（SE）块，它通过显式地模拟通道之间的相互依赖性，">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_10.png">
<meta property="article:published_time" content="2024-02-14T04:39:03.000Z">
<meta property="article:modified_time" content="2024-02-14T04:39:03.000Z">
<meta property="article:author" content="Chitose">
<meta property="article:tag" content="演示">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_10.png"><link rel="shortcut icon" href="https://www.fomal.cc/favicon.ico"><link rel="canonical" href="https://www.chitose.cn/SENet-paper/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":230},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'SENet-paper',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-02-14 12:39:03'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><link rel="stylesheet" href="https://www.fomal.cc/static/css/runtime.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.0.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Face.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">94</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/todolist/"><i class="fa-fw fas fa-link"></i><span> 计划</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_10.png')"><nav id="nav"><span id="blog-info"><a href="/" title="Chitose-Blog"><span class="site-name">Chitose-Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/comments/"><i class="fa-fw fas fa-envelope-open"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/todolist/"><i class="fa-fw fas fa-link"></i><span> 计划</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">SENet-paper</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-02-14T04:39:03.000Z" title="发表于 2024-02-14 12:39:03">2024-02-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-02-14T04:39:03.000Z" title="更新于 2024-02-14 12:39:03">2024-02-14</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Paper/">Paper</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">9.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>29分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="SENet-paper"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="squeeze-and-excitation-networks">Squeeze-and-Excitation
Networks</h1>
<blockquote>
<p>挤压 - 激发网络/SE网络</p>
</blockquote>
<h2 id="摘要">摘要</h2>
<p>卷积神经网络建立在卷积操作的基础上，卷积操作通过融合空间和通道信息，从局部感受野中提取信息。为了增强网络的表征能力，许多现有工作都表明<strong>增强空间编码的好处</strong>。在这项工作中，<strong>我们专注于通道</strong>，并提出了一个新的架构单元，我们称之为<strong>“压缩-激励”（SE）块，</strong>它通过<strong>显式地模拟通道之间的相互依赖性，自适应地重新校准通道特征响应。</strong>我们证明，通过堆叠这些块，我们可以构建在具有挑战性数据集上表现极为出色的SENet架构。关键的是，我们发现SE块为现有最先进的深度架构带来了显著的性能改进，并且只需少量的计算成本。SENet构成了我们ILSVRC
2017分类提交的基础，它赢得了第一名，并显著降低了前5名错误率至2.251%，相比2016年的获胜作品实现了约25%的相对改进。</p>
<blockquote>
<ul>
<li>SE块通过专注于<strong>通道间的相互依赖性</strong>，并自适应调整特征响应来增强网络的表征能力</li>
<li>SENet利用这种架构单元，展现了在处理复杂数据集时的优异性能</li>
<li>SE Block可<strong>嵌入堆叠在很多经典的神经网络中</strong>如Inception
Module、ResNet等构成SENet，在多个数据集上表现良好</li>
</ul>
</blockquote>
<h2 id="引言">1 引言</h2>
<p>卷积神经网络（CNNs）已经证明对于处理各种视觉任务是有效的模型。对于每个卷积层，一组滤波器被学习用来表达沿输入通道的局部空间连接模式。换言之，卷积滤波器应该是通过融合空间和通道方面的信息在局部感受野中形成信息丰富的组合。通过堆叠一系列的卷积层，交错着非线性和降采样，CNN能够捕获具有全局感受野的层次化模式，这些模式是强大的图像描述符。最近的研究表明，网络的性能可以通过显式嵌入学习机制得到提升，这些机制有助于捕捉空间相关性，无需额外的监督。其中一种方法是通过在Inception架构中嵌入多尺度处理过程，证明了网络可以通过在其模块中嵌入多尺度处理过程来达到竞争性的准确度。更多的近期工作致力于更好地建模空间依赖性【1,
27】并纳入空间注意力【17】。</p>
<p>与这些方法相反，我们通过引入一种新的架构单元，即“挤压-激励”（Squeeze-and-Excitation，SE）块，调查了架构设计的不同方面——通道关系。我们的目标是通过显式建模其卷积特征之间的相互依赖性来提高网络的表征能力。为了实现这一点，我们提出了一种机制，允许网络执行特征重标定（feature
recalibration），通过该机制，它可以学习使用全局信息来选择性地强调有信息的特征并抑制不太有用的特征。</p>
<blockquote>
<ul>
<li>SE块，旨在通过<strong>改进通道间的相互依赖性</strong>来增强网络的表征能力。</li>
<li>通过<strong>特征重标定机制</strong>，使得网络能够更有效地利用全局信息，从而提升对图像的描述能力。</li>
<li>与传统的空间依赖性和注意力机制不同，专注于通道关系的建模和优化</li>
</ul>
</blockquote>
<p>SE块的基本结构如图1所示。对于任何给定的变换<span
class="math inline">\(F_{tr}: \mathbf{X} \rightarrow
\mathbf{U}\)</span>，其中<span class="math inline">\(\mathbf{X} \in
\mathbb{R}^{W&#39;\times H&#39;\times C&#39;}\)</span>，<span
class="math inline">\(\mathbf{U} \in \mathbb{R}^{W\times H\times
C}\)</span>（例如，一组卷积），我们可以构建一个相应的SE块来执行特征重标定，如下所述。首先将特征<span
class="math inline">\(\mathbf{U}\)</span>通过一个挤压操作（squeeze
operation）传递，该操作聚合了跨空间维度<span class="math inline">\(W
\times
H\)</span>的特征图，以产生一个通道描述符。该描述符嵌入了通道特征响应的全局分布，使来自网络全局感受野的信息可以被其低层次的层利用。这之后是一个激励操作（excitation
operation），在该操作中，为每个通道学习的样本特定激活，通过基于通道依赖性的自我门控机制（self-gating
mechanism），来控制每个通道的激励。然后，这些特征图<span
class="math inline">\(\mathbf{U}\)</span>​被重新加权以生成SE块的输出，该输出可以直接馈送到后续层。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-f1.png" /></p>
<blockquote>
<p>图 1. 压缩和激励（Squeeze-and-Excitation, SE）模块</p>
</blockquote>
<p><strong>一个SE网络可以通过简单堆叠SE构建模块的集合生成。SE块也可以在架构的任何深度处作为原始块的直接替代品使用。</strong>然而，尽管构建块的模板是通用的，正如我们在第6.3节中展示的，<strong>它在不同深度处扮演的角色会根据网络的需求进行调整。</strong>在早期层，它学会激发信息性特征，在类不可知的方式中增强共享的低级表示。在后续层，SE块变得越来越专门化，并且以高度类别特定的方式对不同输入做出响应。因此，通过整个网络累积的SE块进行特征重校准的益处是连续的。</p>
<p>开发新的CNN架构是一个具有挑战性的工程任务，通常涉及选择许多新的超参数和层配置。与此相比，<strong>上面概述的SE块的设计是简单的，并且可以直接与现有的最先进的架构一起使用，其卷积层可以通过直接用SE对应块替换来加强。</strong>此外，如第4节所展示，SE块在计算上是轻量级的，并且仅在模型复杂性和计算负担上引入了轻微的增加。为了支持这些说法，我们开发了几个SENet，即SE-ResNet，SE-Inception，SE-ResNeXt和SE-Inception-ResNet，并在ImageNet
2012数据集上进行了SENet的广泛评估【30】。进一步地，为了展示SE块的一般应用性，我们还展示了超越ImageNet的结果，表明提出的方法不限于特定的数据集或任务。</p>
<p>使用SENet，我们在ILSVRC
2017分类竞赛中赢得了第一名。我们表现最佳的模型集合在测试集上达到了2.251%的前5错误率。这代表了与前一年获胜者（前5错误率为2.991%）相比约25%的相对改善。我们的模型和相关材料已经向研究社区开放。</p>
<blockquote>
<ul>
<li><p>研究灵感</p>
<ul>
<li>最近研究表明，通过将<strong>学习机制整合到有助于捕捉特征间空间相关性的网络中，CNN产生的表征可以得到加强。</strong>（例：Inception架构将多尺度处理合并到网络模块以提升性能）</li>
<li>进一步工作，寻求更好的模型空间依赖，并将<strong>空间注意力</strong>融入网络结构。</li>
</ul></li>
<li><p>SE块通过<strong>挤压和激励</strong>操作改进CNN，允许网络更有效地利用全局信息和通道之间的依赖关系。</p></li>
<li><p>这种方法既可以增强网络的整体性能，也能在保持模型计算效率的同时细化特征表征。</p></li>
<li><p>SE块的设计灵活，可以轻松集成到各种CNN架构中，证明了其在不同任务和数据集上的广泛适用性。</p></li>
<li><p>通过在多个重要的视觉识别任务中展示显著的性能提升，SENet的成功突显了SE块在深度学习领域的价值。</p></li>
</ul>
</blockquote>
<h2 id="相关工作"><strong>2. 相关工作</strong></h2>
<p>深度架构。大量的工作表明，通过以一种简化深层特征学习的方式重构卷积神经网络的架构可以获得显著的性能改善。VGGNet【35】和Inception模型【39】展示了通过增加深度可以获得的益处，显著超越了2014年ILSVRC上的先前方法。批量标准化（BN）【14】改善了通过深度网络的梯度传播，通过插入单元来调节层输入稳定了学习过程，这使得能够进一步实验更深层次。He等人【9,10】显示通过重构架构来学习残差函数是有效的，他们使用基于身份的跳跃连接，这简化了跨单元的信息流。最近，网络层间连接的重新表述已被证明能进一步改善深度网络的学习和表征特性【5,12】。</p>
<p>研究的另一分支探索了调整网络模块组件的功能形式的方法。分组卷积可以用来增加基数（变换集的大小）【13,
43】，以学习更丰富的表征。多分支卷积可以被理解为这一概念的概括，使卷积操作的组合更为灵活【14,
38, 39,
40】。跨通道的相关性通常被映射为特征的新组合，要么是依赖于空间结构【6,
18】，要么是通过使用标准的卷积滤波器【22】与(1
)卷积联合使用。尽管大量的研究集中在减少模型和计算复杂度的目标上，这种方法反映了一个假设，即通道关系可以被构成为与局部感受野相关的实例不可知函数的组合。相比之下，我们声称提供网络一个机制来显式建模通道间使用全局信息的动态、非线性依赖性可以简化学习过程，并显著增强网络的表征能力。</p>
<blockquote>
<ul>
<li>通过增加深度和改进架构设计（如VGGNet、Inception、残差学习），已经展示了显著的性能提升。</li>
<li>方法如批量标准化和网络层间连接的重新表述进一步改善了深度网络的学习过程。</li>
<li>分组卷积和多分支卷积增加了模型表征的丰富性和灵活性。</li>
<li>通过映射跨通道相关性和引入新的架构单元（如SE块），研究提出了利用全局信息和通道间动态非线性依赖性的方法，这旨在简化学习过程并显著提升表征能力。</li>
</ul>
</blockquote>
<p><strong>注意力和门控机制</strong></p>
<p>注意力可以广泛地被视为一种<strong>工具</strong>，它可以偏向资源分配，集中于输入信号中最具信息量的部分。这样的机制的发展和理解一直是<strong>神经科学</strong>界长期的研究领域【15,
16,
28】，并且在近年来作为深度神经网络的一个有力的补充而受到<strong>显著的关注</strong>【20,
25】。注意力已经被证明能够<strong>提高一系列任务的性能</strong>，从<u>图像中的定位和理解</u>【3,
17】到<u>基于序列的模型</u>【2,
24】。它通常<strong>与门控功能</strong>（例如 softmax 或
sigmoid）结合使用，并通过顺序技术【1,
37】实现。近期的工作显示它适用于诸如<u>图像标题生成【4,
44】和唇读【7】</u>的任务，这些任务中它能有效地整合多模态数据。在这些应用中，它通常用于一个或多个<strong>表示更高层次抽象的层</strong>之上，用于模态间适应性。<u>高速公路网络【36】</u>采用一种门控机制来调节快捷连接，从而使非常深的架构的学习成为可能。<u>Wang
等人【42】引入了一种强大的主干-掩膜注意力机制，使用沙漏模块【27】，灵感来自其在语义分割中的成功</u>。这个高容量单元被插入深度残差网络的中间阶段。相比之下，我们提出的
SE
块是一种<strong>轻量级的门控机制</strong>，专门用于以计算效率高的方式建模通道间关系，并设计用于增强整个网络中模块的表征能力。</p>
<blockquote>
<ul>
<li>在目前的神经网络模型中，可以将max
pooling和gating机制近似地看作是自下而上的基于显著性的注意力机制。</li>
</ul>
</blockquote>
<h2 id="压缩和激励模块"><strong>3. 压缩和激励模块</strong></h2>
<h3 id="传统卷积操作">3.1 传统卷积操作</h3>
<p>压缩和激励（Squeeze-and-Excitation, SE）模块是一个可以为任何给定变换
<span class="math inline">\(F_{tr} : \mathbf{X} \rightarrow
\mathbf{U}\)</span>，其中 <span class="math inline">\(\mathbf{X} \in
\mathbb{R}^{W&#39; \times H&#39; \times C&#39;}\)</span>，<span
class="math inline">\(\mathbf{U} \in \mathbb{R}^{W \times H \times
C}\)</span> 构建的计算单元。为了陈述上的简洁，在接下来的记号中，我们假设
<span class="math inline">\(F_{tr}\)</span> 为一个标准的卷积操作符。让
<span class="math inline">\(\mathbf{V} = [v_1, v_2, \dots, v_C]\)</span>
表示学到的滤波器核集合，其中 <span class="math inline">\(v_c\)</span>
指的是第 c 个滤波器的参数。我们可以写出 <span
class="math inline">\(F_{tr}\)</span> 的输出为 <span
class="math inline">\(\mathbf{U} = [u_1, u_2, \dots, u_C]\)</span>，其中
<span class="math display">\[
u_c = v_c * \mathbf{X} = \sum_{s=1}^{C&#39;} v_c^s * x^s \quad (1)
\]</span></p>
<p>这里 * 表示卷积，<span class="math inline">\(v_c = [v_c^1, v_c^2,
\dots, v_c^{C&#39;}]\)</span> 和 <span class="math inline">\(\mathbf{X}
= [x^1, x^2, \dots,
x^{C&#39;}]\)</span>（为了简化记号，省略了偏置项）。这里 <span
class="math inline">\(v_c^s\)</span> 是一个 2D
空间核，因此代表了单个通道 <span class="math inline">\(v_c\)</span>
的输出作用于相应通道 <span class="math inline">\(x^s\)</span>
的信号。由于输出是通过所有通道的总和，通道依赖性隐式地嵌入在 <span
class="math inline">\(v_c\)</span>
中，但这些依赖性与通过滤波器捕获的空间相关性纠缠在一起。我们的目标是确保网络能够增加对信息特征的敏感性，以便它们可以被随后的变换利用，并抑制不太有用的特征。我们提出通过显式建模通道间依赖性来重新校准滤波器响应来实现这一点，这一过程在它们被馈入到下一个变换之前分为压缩和激励两个步骤。SE构建块的示意图如图
1 所示。</p>
<h3 id="压缩全局信息嵌入"><strong>3.2. 压缩：全局信息嵌入</strong></h3>
<p>为了解决利用通道依赖性的问题，我们首先考虑输出特征中每个通道的信号。<strong>每个学习到的滤波器都以一种独特的方式操作输出特征。</strong>变换输出
<span class="math inline">\(\mathbf{U}\)</span>
的每个单元无法利用其局部感受野之外的上下文信息。这在网络的底层尤为严重，其接受域大小较小。</p>
<p>为了缓解这个问题，我们提出<strong>将全局空间信息压缩成通道描述符</strong>。这通过使用<strong>全局平均池化</strong>来生成通道统计数据来实现。形式上，一个统计量
<span class="math inline">\(z \in \mathbb{R}^C\)</span> 是通过在空间维度
<span class="math inline">\(W \times H\)</span> 上压缩 <span
class="math inline">\(\mathbf{U}\)</span> 来生成的，其中第 c
个元素由下式计算：</p>
<p><span class="math display">\[
z_c = F_{sq}(u_c) = \frac{1}{W \times H} \sum_{i=1}^{W} \sum_{j=1}^{H}
u_c(i,j) \quad (2)
\]</span></p>
<p><strong>讨论：</strong> 变换输出 <span
class="math inline">\(\mathbf{U}\)</span>
可以被解释为局部描述符的集合，其统计数据对于整个图</p>
<p>像是具有表现力的。利用这样的信息在特征工程工作中是普遍存在的【31, 34,
45】。我们选择最简单的，全局平均池化，尽管可以采用更复杂的聚合策略。</p>
<blockquote>
<p>Fsq操作就是使用通道的<strong>全局平均池化</strong>，将包含全局信息的W×H×C
的特征图直接压缩成一个1×1×C的特征向量，即将每个二维通道变成一个具有全局感受野的数值，此时1个像素表示1个通道，屏蔽掉空间上的分布信息，更好的利用通道间的相关性。</p>
</blockquote>
<h3 id="激励自适应重标定"><strong>3.3. 激励：自适应重标定</strong></h3>
<p>为了利用在压缩操作中聚合的信息，我们用第二个操作来跟进，其目的是充分捕捉通道间依赖性。为了实现这一目标，函数必须满足两个条件：首先，它必须灵活（特别是，它必须能够学习通道间的非线性互动），其次，它必须学习非相互排斥的多通道关系（尤其是，它必须能够学习单热激活）。为了满足这些标准，我们选择采用一个简单的门控机制，具有sigmoid激活：</p>
<p><span class="math display">\[
s = F_{ex}(z, \mathbf{W}) = \sigma(g(z, \mathbf{W})) =
\sigma(\mathbf{W}_2 \delta(\mathbf{W}_1 z)) \quad (3)
\]</span></p>
<p>其中 <span class="math inline">\(\delta\)</span> 代表 ReLU
函数【26】，<span class="math inline">\(\mathbf{W}_1 \in
\mathbb{R}^{F&#39; \times C}\)</span> 和 <span
class="math inline">\(\mathbf{W}_2 \in \mathbb{R}^{C \times
F&#39;}\)</span>。为了限制模型复杂性并帮助泛化，我们通过形成一个瓶颈（bottleneck）来参数化门控机制，该瓶颈具有两个全连接（FC）层围绕非线性，即具有参数
<span class="math inline">\(\mathbf{W}_1\)</span> 的降维层，以及具有参数
<span class="math inline">\(\mathbf{W}_2\)</span>
的维数增加层。最终的块输出是通过用激活值重新缩放变换输出 <span
class="math inline">\(\mathbf{U}\)</span> 获得的：</p>
<p><span class="math display">\[
\hat{x}_c = F_{scale}(u_c, s_c) = s_c \cdot u_c \quad (4)
\]</span></p>
<p>其中 <span class="math inline">\(\hat{\mathbf{X}} = [\hat{x}_1,
\hat{x}_2, \dots, \hat{x}_C]\)</span> 和 <span
class="math inline">\(F_{scale}(u_c, s_c)\)</span> 指的是特征图 <span
class="math inline">\(u_c \in \mathbb{R}^{W \times H}\)</span> 和标量
<span class="math inline">\(s_c\)</span>​ 之间的通道-wise乘法。</p>
<blockquote>
<p><strong>目的:</strong>为了利用在"squeeze"操作中聚合的信息，接着进行Excitation操作，来完全捕获通道依赖关系。</p>
<p><strong>方法：</strong>为实现上述目标，函数必须符合两个标准：</p>
<p>(1）灵活性：它必须能够学习通道之间的非线性相互作用</p>
<p>(2）必须学习一种非互斥关系：因为我们希望确保允许强调多个通道不同重要程度(而不是强制一个one-hot激活)。因为我们不光要学习特征，还要学习通道之间信息的相关性。</p>
<p>为了满足这两个条件，这篇论文这里采用<strong>两个全连接层+两个激活函数</strong>组成的结构输出和输入特征同样数目的权重值，也就是每个特征通道的权重系数。</p>
<h4 id="excitation操作">Excitation操作</h4>
<p>基于特征通道间的相关性，每个特征通道生成一个权重，用来代表特征通道的重要程度。由原本全为白色的C个通道的特征，得到带有不同深浅程度的颜色的特征向量，也就是不同的重要程度。</p>
<p>(1)第一个FC层：ReLU （δ）</p>
<p>(2)第二个FC层：Sigmoid（σ）</p>
</blockquote>
<h3 id="典范se-inception和se-resnet"><strong>3.4.
典范：SE-Inception和SE-ResNet</strong></h3>
<p>SE模块的灵活性意味着它可以直接应用于标准卷积变换之外的变换。为了说明这一点，我们通<strong>过将SE块集成到两种流行的网络系列——Inception和ResNet中来开发SENet。</strong>SE块通过将变换<span
class="math inline">\(F_{tr}\)</span>看作完整的Inception模块（见图2）来为Inception网络构建。通过对架构中的每个这样的模块进行此更改，我们构建了一个SE-Inception网络。残差网络及其变体已被证明在学习深度表示方面非常有效。我们开发了一系列与ResNet【9】，ResNeXt【43】和Inception-ResNet【38】集成的SE块。图3展示了一个SE-ResNet模块的示意图。这里，SE块变换<span
class="math inline">\(F_{tr}\)</span>​被认为是残差模块的非恒等分支。压缩和激励都在与恒等分支相加之前执行。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-f2.png" /></p>
<blockquote>
<p>图 2. 原始Inception模块（左）与SE-Inception模块（右）的架构图。</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-f3.png" /></p>
<blockquote>
<p>图 3. 原始残差模块（左）与SE-ResNet模块（右）的架构图。</p>
</blockquote>
<h2 id="模型与计算复杂性"><strong>4. 模型与计算复杂性</strong></h2>
<p>通过堆叠一系列SE块，可以构建一个SENet。实践中，它是通过用相应的SE对应块（即SE残差块）替换每个原始块来生成的。我们在表1中描述了SE-ResNet-50和SE-ResNeXt-50的架构。为了使提出的SE块在实践中可行，它必须提供可接受的模型复杂性和计算开销，这对于可扩展性是重要的。为了说明这种开销，我们以ResNet-50和SE-ResNet-50之间的比较为例，其中SE-ResNet-50的准确性显然优于ResNet-50，并且接近更深的ResNet-101网络（如表2所示）。ResNet-50在一个224x224像素输入图像的单次前向传递中需要约3.86
GFLOPs。每个SE块在压缩阶段使用全局平均池化操作，在激励阶段使用两个小的全连接层，接着是一个廉价的通道-wise缩放操作。在一个训练小批量中，SE-ResNet-50需要约3.87
GFLOPs，与原始ResNet-50相比只增加了0.26%的相对增长。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-t1.png" /></p>
<blockquote>
<p>表 1.
（左）ResNet-50。（中）SE-ResNet-50。（右）具有32×4d模板的SE-ResNeXt-50。残差构建块内部的形状和具体参数设置操作在括号内列出，而每个阶段堆叠块的数量则在外部呈现。紧跟在fc后面的内括号表示SE模块中两个全连接层的输出维度。</p>
</blockquote>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-t2.png" /></p>
<blockquote>
<p>表 2.
在ImageNet验证集上的单次裁剪错误率（%）及复杂性比较。原始列指的是原始论文中报告的结果。为了实现公平比较，我们重新训练了基线模型并报告了重新实现列中的分数。SENet列指的是添加了SE块的相应架构。括号中的数字表示与重新实现的基线的性能改进。†表示该模型已在非黑名单验证集子集上评估（这在[38]中讨论得更详细），这可能会略微改善结果。</p>
</blockquote>
<p>在实践中，使用256张图像的训练小批量，通过ResNet-50的前向和后向单次传递分别需要190ms和209ms，而对于SE-ResNet-50（两者都在8个NVIDIA
Titan X
GPU上执行）则分别需要。我们认为这是一个合理的开销，因为全局池化和小内积操作在现有的GPU库中优化程度较低。此外，由于它对嵌入式设备应用的重要性，我们还为每个模型基准测试了CPU推理时间：对于一个224x224像素输入图像，ResNet-50需要164ms，而SE-ResNet-50则需要167ms。SE块带来的额外开销是由其对模型性能的贡献所证明的，这一点将在第6节中详细讨论。</p>
<p>接下来，我们考虑了由提出的块引入的额外参数。所有额外的参数都包含在门控机制的两个全连接层中，这些层只构成了总网络容量的一小部分。更具体地，引入的额外参数数量由以下公式给出：</p>
<p>$$ _{s=1}^{S} N_s C_s</p>
<p>^2 (5) $$</p>
<p>其中 ( r ) 表示减少比例（在我们所有的实验中我们设置 ( r ) 为16），( S
) 表示阶段数（每个阶段指的是具有共同空间维度的块集合），( C_s ) 表示第 (
s ) 阶段输出通道的维度，( N_s )
表示重复块的数量。总体而言，SE-ResNet-50引入了大约250万个额外参数，超出了ResNet-50所需的约2500万参数，相当于总参数数量的约10%增加。这些额外参数的大多数来自网络的最后阶段，其中激励是在通道维度最大的地方进行的。然而，我们发现可以在性能上只有微小的成本（ImageNet数据集上&lt;0.1%的top-1错误）就去掉SE块的相对昂贵的最后阶段，以减少相对参数增加到约4%，这在参数使用是关键考虑因素的情况下可能是有用的。</p>
<h2 id="实现"><strong>5. 实现</strong></h2>
<p>在训练过程中，我们遵循标准实践，执行随机大小裁剪的数据增强[39]至224x224像素（对于Inception-ResNet-v2[38]和SE-Inception-ResNet-v2为299x299）和随机水平翻转。输入图像通过均值通道减法进行标准化。此外，我们采纳了文献[32]中描述的针对小批量采样的数据平衡策略，以补偿类别分布的不均匀性。网络在我们的分布式学习系统“ROCS”上训练，该系统能够有效地进行大型网络的并行训练。使用同步SGD优化，动量为0.9，小批量尺寸为1024（分割为每个GPU32张图像，跨4台服务器，每台包含8个GPU）。初始学习率设定为0.6，并且每10个周期降低一次。所有模型均从头开始训练100个周期，使用文献[8]中描述的权重初始化策略。</p>
<h2 id="实验"><strong>6. 实验</strong></h2>
<p>在这一节中，我们在ImageNet
2012数据集[30]上进行了广泛的实验，目的有二：首先，探索所提出的SE块对基本网络不同深度的影响；其次，研究其与当前最先进的网络架构集成的能力，旨在公平比较SENet和非SENet，而不是推动性能。接下来，我们展示了ILSVRC
2017分类任务的结果和细节。此外，我们还在Places365-Challenge场景分类数据集[48]上进行了实验，以调查SENet如何能够泛化到其他数据集。最后，我们调查了激励的作用并提供了一些基于实验现象的分析。</p>
<h3 id="imagenet分类"><strong>6.1. ImageNet分类</strong></h3>
<p>ImageNet
2012数据集包含了128万个训练图像和5万个验证图像，来自1000个类别。我们在训练集上训练网络，并报告了使用中心裁剪评估在验证集上的top-1和top-5错误率，其中224x224像素被从每张图像的较短边首先调整为256（对于Inception-ResNet-v2和SE-Inception-ResNet-v2调整为352）的图像中裁剪出来。</p>
<p><strong>网络深度。</strong>
我们首先将SE-ResNet与一系列标准ResNet架构进行比较。每个ResNet及其对应的SE-ResNet都使用相同的优化方案进行训练。不同网络在验证集上的表现如表2所示，显示出SE块在不同深度上一致地提高性能，而计算复杂性的增加极小。</p>
<p>值得注意的是，SE-ResNet-50在单次裁剪top-5验证错误率上实现了6.62%的成绩，超过了ResNet-50（7.48%）的0.86%，并接近于深度更大的ResNet-101网络（6.52%
top-5错误）仅用了一半的计算开销（3.87 GFLOPs vs. 7.58
GFLOPs）。这种模式在更深层次重复，其中SE-ResNet-101（6.07%
top-5错误）不仅击败了ResNet-101（6.34%
top-5错误），也超过了更深的ResNet-152网络（6.45%
top-5错误）0.27%。图4展示了SE-ResNet和ResNet的训练和验证曲线。虽然SE块本身</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-f4.png" /></p>
<blockquote>
<p>图 4.
在ImageNet上的训练曲线。（左）：ResNet-50和SE-ResNet-50；（右）：ResNet-152和SE-ResNet-152。</p>
</blockquote>
<p>增加了深度，但它们以极其计算效率高的方式这样做，并且即使在基础架构扩展深度的点上也能获得良好的回报。更重要的是，这些性能提升在整个训练过程中是一致的，表明通过SE块引入的改进可以结合在基础架构中添加更多深度上使用。</p>
<p><strong>与现代架构的集成。</strong>
我们接下来调查了将SE块与另外两种最先进的架构，Inception-ResNet-v2[38]和ResNeXt[43]相结合的效果。Inception架构构建了模块化的卷积，作为多分支组合的特征过滤器，反映了空间假设[6]，即空间相关性和跨通道相关性可以独立映射。相比之下，ResNeXt架构主张可以通过聚合稀疏连接（在通道维度）的卷积特征组合获得更丰富的表征。这两种方法都在模块中引入了先前构建的相关性。我们构建了SENet等价物，SE-Inception-ResNet-v2和SE-ResNeXt（SE-ResNeXt-50（32x4d）的配置在表1中）。与之前的实验一样，使用相同的优化方案。表2展示了当引入SE块到两种架构中时的显著性能提升。特别是，SE-ResNeXt-50的top-5错误率为5.49%，优于其直接对应的ResNeXt-50（5.90%
top-5错误）以及更深的ResNeXt-101（5.57%
top-5错误），模型几乎增加了一倍的参数而计算开销仅增加了一半。至于实验中的Inception-ResNet-v2，我们推测裁剪策略的不同可能导致了他们报告的结果和我们重实现结果之间的差距，因为他们的原始图像尺寸在[38]中没有被澄清，而我们在裁剪299x299区域时是从一个相对较大的图像中裁剪（其中较短边先调整为352）。SE-Inception-ResNet-v2（4.79%
top-5错误）的表现超过了我们重实现的Inception-ResNet-v2（5.21%
top-5错误）0.42%（相对改善8.1%），以及[38]中报告的结果。每个网络的优化曲线如图5所示，展示了SE块在整个训练过程中提供的改善的一致性。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-f5.png" /></p>
<blockquote>
<p>图 5.
在ImageNet上的训练曲线。（左）：ResNeXt-50和SE-ResNeXt-50；（右）：Inception-ResNet-v2和SE-Inception-ResNet-v2。</p>
</blockquote>
<p>最后，我们通过对BN-Inception架构[14]进行实验来评估SE块在非残差网络上的效果，这提供了在较低模型复杂度上的良好性能。结果的比较显示在表2中，并且训练曲线在图6中展示，显示出在残差架构中出现的同样现象。特别是，SE-BN-Inception在top-5错误率上实现了7.14%的低值，相比于BN-Inception的错误率为7.89%。这些实验表明，SE块引入的改进可以与广泛的残差和非残差基础架构结合使用。此外，这个结果对于残差和非残差架构都是有效的。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-f6.png" /></p>
<blockquote>
<p>图 6. 在ImageNet上的BN-Inception和SE-BN-Inception的训练曲线。</p>
</blockquote>
<p><strong>关于ILSVRC 2017分类竞赛的结果</strong></p>
<p>ILSVRC是一个年度计算机视觉比赛，它已经成为模型发展的肥沃土壤，特别是在图像分类方面。ILSVRC
2017分类任务的训练和验证数据来自ImageNet
2012数据集，而测试集包含了额外的未标记的100K图像。为了比赛的目的，使用前五错误率指标来排名参赛作品。SENet构成了我们提交到挑战赛中并赢得第一名的基础。我们的获胜作品包括一个使用了小型SENet集合，这些SENet通过一个标准的多尺度和多作物融合策略来获得22.251%的前五错误率和该测试集的最优结果。这代表相比2016年的获胜者（2.992%的前五错误率）约25%的相对改进。我们的一个高性能网络是通过整合SE模块与一个改进的ResNeXt构建的（修改的细节在附录A中提供）。我们将提出的架构与现有的最佳模型在ImageNet验证集上进行了比较，见表3。我们的模型在使用224x224中心作物评估的情况下（首先将图像短边缩放到256），实现了18.68%的前一错误率和4.47%的前五错误率。为了能够与之前的模型公平比较，我们也提供了一个320x320中心作物评估，获得了最低的错误率，前一错误率和前五错误率分别是17.28%和3.79%。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-t3.png" /></p>
<blockquote>
<p>表 3.
在ImageNet验证集上的先进CNN单次裁剪错误率。测试裁剪的大小为224×224及320×320
/
299×299，如[10]所示。我们提出的模型，SENet，在之前的工作上显示了显著的性能改进。</p>
</blockquote>
<h3 id="场景分类"><strong>6.2 场景分类</strong></h3>
<p>由于ImageNet数据集的大部分由单个对象主导的图像组成，为了在更多样化的场景中评估我们提出的模型，我们还在Places365-Challenge数据集上进行了场景分类评估。这个数据集包含了800万个训练图像和36,500个验证图像，涵盖365个类别。与分类相比，场景理解任务可以更好地评估模型的泛化能力和抽象处理能力，因为它需要捕获更复杂的数据关联并对更高水平的外观变化具有鲁棒性。我们使用ResNet-152作为评估SE块效果的强基准，并遵循评估协议[33]。表4显示了在给定任务上训练的ResNet-152模型和SE-ResNet-152模型的结果。特别是，SE-ResNet-152（11.01%的前五错误率）在验证错误上比ResNet-152（11.61%的前五错误率）低，提供了证据说明SE块可以在不同的数据集上表现良好。这支持了SE块的优越性，它们甚至超越了先前的最佳模型Places-365-CNN[33]，该模型在此任务上的前五错误率是11.48%。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-t4.png" /></p>
<blockquote>
<p>表 4. 在Places365验证集上的单次裁剪错误率（%）。</p>
</blockquote>
<h3 id="分析与讨论">6.3 分析与讨论</h3>
<p>缩减比率。缩减比率<span
class="math inline">\(r\)</span>是一个重要的超参数，它允许我们在模型中调整SE块的容量和计算成本。为了研究这种关系，我们基于SE-ResNet-50架构进行了一系列实验，测试了不同<span
class="math inline">\(r\)</span>值的效果。表5中的比较揭示了性能并不是随着容量的增加而单调提高。这很可能是因为允许SE块过度拟合训练集中的通道间依赖关系。特别地，我们发现设置<span
class="math inline">\(r=16\)</span>​可以在准确性和复杂性之间取得良好的平衡，因此我们在所有实验中都使用了这个值。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-t5.png" /></p>
<blockquote>
<p>表 5.
在ImageNet验证集上的单次裁剪错误率（%）及SE-ResNet-50架构在不同缩减比率r下的相应模型大小。这里的原始指的是ResNet-50。</p>
</blockquote>
<p>激活的作用。虽然SE块已被经验性地显示可以改善网络性能，我们还希望在实践中理解自我门控激活机制的运作。为了提供一个更清晰的SE块行为图像，我们在这一节研究了从SE-ResNet-50模型中采样的示例激活，并检查了它们在不同类别的不同块中的分布。具体来说，我们从ImageNet数据集中采样了四个类别，这些类别展示了语义和外观多样性，分别是金鱼、哈巴狗、飞机和悬崖（示例图像见图7）。然后我们从验证集中为每个类别抽取50个样本，并计算在均匀采样的通道中最后一个SE块的平均激活（时间上采样）并绘制它们的分布图（见图8）。为了参考，我们还绘制了所有1000个类别平均激活的分布。</p>
<p><img
src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/senet-f7.png" /></p>
<blockquote>
<p>图 7. ImageNet四个类别的示例图片。</p>
</blockquote>
<p>在最后网络阶段的SE_5_2中观察到一种趋势，表现为向饱和状态过渡，大多数激活值接近1并且剩余激活值接近0。如果所有激活都取值1，这个块将变成一个标准残差块。在网络末端的SE_5_3（紧接着全局池化之前的分类器），观察到一个类似的现象，即在不同类别中，出现了一个共同模式（在分类器之前调优），表明在这些类别中可以通过分类器进行调整。这表明SE_5_2和SE_5_3在提供网络重校准方面不如之前的块那么重要。这一发现与第四部分的实证研究结果一致，即通过移除网络最后阶段的SE块，整体参数数量可以大幅减少，而性能损失却非常小（&lt;
0.1%的前一错误率）。</p>
<h2 id="结论">7 结论</h2>
<p>在本文中，我们提出了SE块，一种新的架构单元，旨在通过启用动态通道级特征校准来提高网络的表示能力。广泛的实验表明SENet在多个数据集上达到了最先进的性能。此外，它们还提供了对先前架构在建模通道级特征依赖性方面的局限性的一些洞察，我们希望这些洞察对其他需要强大判别特征的任务也有用。最后，SE块引入的特征重要性可能对相关领域如网络修剪压缩等有所帮助。</p>
<h2 id="致谢">致谢</h2>
<p>我们要感谢Zisserman教授为本文提供的宝贵评论以及Samuel
Albanie的讨论和写作编辑帮助。我们还要感谢李超对训练系统记忆优化的贡献。李深的工作得到了国家情报总监办公室、高级研究项目代理（IARPA），通过情报高级研究项目活动（ODNI），合同编号2014-14071600010支持。本文所包含的观点和结论只代表作者，并不应被解释为必然代表ODNI、IARPA或美国政府的官方政策或认可，无论是明示还是暗示。美国政府拥有此作品的版权，尽管有版权声明</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://www.chitose.cn">Chitose</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://www.chitose.cn/SENet-paper/">https://www.chitose.cn/SENet-paper/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.chitose.cn" target="_blank">Chitose-Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_10.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/sever/" title="sever"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_9.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">sever</div></div></a></div><div class="next-post pull-right"><a href="/ResNeXt-paper/" title="ResNeXt-paper"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_7.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">ResNeXt-paper</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/Face.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Chitose</div><div class="author-info__description">Hahaha</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">94</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">4</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/chitose-r"><i class="fab fa-github"></i><span>🛴/前往小家..</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/chitose-r" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:171450290@qq.com" target="_blank" title="Email"><i class="fa-solid fa-square-envelope" style="color: #4a7dbe;"></i></a><a class="social-icon" href="/qq/" target="_blank" title="QQ"><i class="fab fa-qq" style="color: #12b7f5;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#squeeze-and-excitation-networks"><span class="toc-text">Squeeze-and-Excitation
Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-text">1 引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-text">2. 相关工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E5%92%8C%E6%BF%80%E5%8A%B1%E6%A8%A1%E5%9D%97"><span class="toc-text">3. 压缩和激励模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%A0%E7%BB%9F%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C"><span class="toc-text">3.1 传统卷积操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E5%85%A8%E5%B1%80%E4%BF%A1%E6%81%AF%E5%B5%8C%E5%85%A5"><span class="toc-text">3.2. 压缩：全局信息嵌入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BF%80%E5%8A%B1%E8%87%AA%E9%80%82%E5%BA%94%E9%87%8D%E6%A0%87%E5%AE%9A"><span class="toc-text">3.3. 激励：自适应重标定</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#excitation%E6%93%8D%E4%BD%9C"><span class="toc-text">Excitation操作</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B8%E8%8C%83se-inception%E5%92%8Cse-resnet"><span class="toc-text">3.4.
典范：SE-Inception和SE-ResNet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E4%B8%8E%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E6%80%A7"><span class="toc-text">4. 模型与计算复杂性</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-text">5. 实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-text">6. 实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#imagenet%E5%88%86%E7%B1%BB"><span class="toc-text">6.1. ImageNet分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%BA%E6%99%AF%E5%88%86%E7%B1%BB"><span class="toc-text">6.2 场景分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%A8%E8%AE%BA"><span class="toc-text">6.3 分析与讨论</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-text">7 结论</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%B4%E8%B0%A2"><span class="toc-text">致谢</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2022 - 2024 By Chitose</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script defer src="/js/cursor.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/Python/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🥩 Python (30)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/C/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🕶️ C (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/Embedded/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">💳 Embedded (1)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/Pytorch/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📯 Pytorch (9)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/Paper/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📰 Paper (28)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/others/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🤡 others (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="https://www.chitose.cn/categories/segmentation/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🔪 segmentation (3)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="https://www.chitose.cn/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(33.333333333333336% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023-12-17-2/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_8.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023-12-17-2/" alt="">第二篇文章</a><div class="blog-slider__text">这是第二篇文章</div><a class="blog-slider__button" href="2023-12-17-2/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="Pytorch-6/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_2.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-19</span><a class="blog-slider__title" href="Pytorch-6/" alt="">Pytorch(6)-张量可微性</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="Pytorch-6/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023-12-17-3/" alt=""><img width="48" height="48" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.jsdelivr.net/gh/chitose-r/pic_bed@master/img/default_cover_5.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-12-17</span><a class="blog-slider__title" href="2023-12-17-3/" alt="">第三篇文章</a><div class="blog-slider__text">这是第三篇文章</div><a class="blog-slider__button" href="2023-12-17-3/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = '/';
  var qweather_key = '6be604177b8a4c3e97c78a352ee324f7';
  var gaud_map_key = '17b299fafade134736e6a1d4acb5ef18';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '113.34532,23.15624';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><p id="ghbdages"><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" data-title="博客框架为Hexo_v6.2.0" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" data-title="主题版本Butterfly_v4.3.1" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&amp;logo=bitdefender" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" data-title="本站采用多线部署，主线路托管于Vercel" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=flat&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="https://dashboard.4everland.org/" style="margin-inline:5px" data-title="本站采用多线部署，备用线路托管于4EVERLAND" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Hosted-4EVERLAND-22DDDD?style=flat&amp;logo=IPFS" alt=""/></a><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" data-title="本站项目由Github托管" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" data-title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可" title=""><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></p>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false});</script></body></html>